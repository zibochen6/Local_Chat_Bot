#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Seeed Wiki ä¼˜åŒ–é—®ç­”ç³»ç»Ÿ
ä½¿ç”¨é¢„ä¿å­˜çš„ FAISS ç´¢å¼•å’Œ Ollama nomic-embed-text æ¨¡å‹
"""

import json
import os
import pickle
import numpy as np
import faiss
import ollama
import time
import re
import sys
import readline  # æ·»åŠ  readline æ”¯æŒï¼Œæä¾›æ›´å¥½çš„è¾“å…¥ä½“éªŒ
import hashlib
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor
import threading
import subprocess
import tempfile
import os

class OptimizedQASystem:
    def __init__(self):
        self.faiss_index = None
        self.faiss_metadata = None
        self.wiki_pages = []
        self.embedding_model = "nomic-embed-text"
        
        # æ€§èƒ½ä¼˜åŒ–ç›¸å…³
        self.embedding_cache = {}  # embedding ç¼“å­˜
        self.answer_cache = {}     # å›ç­”ç¼“å­˜
        self.cache_lock = threading.Lock()  # ç¼“å­˜é”
        self.executor = ThreadPoolExecutor(max_workers=2)  # çº¿ç¨‹æ± 
        
        # æµå¼æ˜¾ç¤ºç›¸å…³
        self.streaming_enabled = True  # æ˜¯å¦å¯ç”¨æµå¼æ˜¾ç¤º
        self.typing_speed = 0.03  # æ‰“å­—é€Ÿåº¦ï¼ˆç§’/å­—ç¬¦ï¼‰
        
        # æ–‡æœ¬è½¬è¯­éŸ³ç›¸å…³
        self.tts_enabled = True  # æ˜¯å¦å¯ç”¨TTSï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        self.tts_voice = "zh"  # è¯­éŸ³ç±»å‹ï¼šzh(ä¸­æ–‡), en(è‹±æ–‡)
        self.tts_speed = 1.0  # è¯­éŸ³é€Ÿåº¦
        self.tts_save_to_file = True  # æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
        self.tts_output_dir = "./audio_output"  # éŸ³é¢‘è¾“å‡ºç›®å½•
        self.tts_format = "wav"  # éŸ³é¢‘æ ¼å¼ï¼šwav, mp3
        
        # è®¾ç½® readline é…ç½®
        self.setup_readline()
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        self.check_data_files()
        
        # æ£€æŸ¥ Ollama æœåŠ¡
        self.check_ollama_service()
        
        # æ£€æŸ¥ TTS å·¥å…·
        self.check_tts_availability()
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        self.initialize_system()
    
    def setup_readline(self):
        """è®¾ç½® readline é…ç½®ï¼Œæä¾›æ›´å¥½çš„è¾“å…¥ä½“éªŒ"""
        try:
            # è®¾ç½®å†å²æ–‡ä»¶
            histfile = os.path.join(os.path.expanduser("~"), ".seeed_qa_history")
            readline.read_history_file(histfile)
            readline.set_history_length(1000)
            
            # è®¾ç½®è‡ªåŠ¨è¡¥å…¨
            readline.parse_and_bind('tab: complete')
            
            # è®¾ç½®è¾“å…¥æç¤ºç¬¦æ ·å¼
            readline.parse_and_bind('set editing-mode emacs')
            
        except Exception as e:
            print(f"âš ï¸  readline è®¾ç½®å¤±è´¥: {str(e)}")
            print("ğŸ’¡ è¾“å…¥ä½“éªŒå¯èƒ½å—é™ï¼Œä½†åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
    
    def safe_input(self, prompt):
        """å®‰å…¨çš„è¾“å…¥å‡½æ•°ï¼Œæä¾›æ›´å¥½çš„é”™è¯¯å¤„ç†"""
        try:
            # å°è¯•ä½¿ç”¨ readline è¾“å…¥
            user_input = input(prompt)
            return user_input.strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
            sys.exit(0)
        except Exception as e:
            print(f"\nâŒ è¾“å…¥é”™è¯¯: {str(e)}")
            return ""
    
    def save_history(self):
        """ä¿å­˜è¾“å…¥å†å²"""
        try:
            histfile = os.path.join(os.path.expanduser("~"), ".seeed_qa_history")
            readline.write_history_file(histfile)
        except Exception:
            pass  # å¿½ç•¥å†å²ä¿å­˜é”™è¯¯
    
    def check_data_files(self):
        """æ£€æŸ¥å¿…è¦çš„æ•°æ®æ–‡ä»¶"""
        required_files = [
            "./data_base/faiss_index.bin",
            "./data_base/faiss_metadata.pkl",
            "./data_base/seeed_wiki_embeddings_db.json"
        ]
        
        missing_files = []
        for file in required_files:
            if not os.path.exists(file):
                missing_files.append(file)
        
        if missing_files:
            print("âŒ ç¼ºå°‘å¿…è¦çš„æ•°æ®æ–‡ä»¶:")
            for file in missing_files:
                print(f"   - {file}")
            print("\nğŸ’¡ è¯·å…ˆè¿è¡Œçˆ¬è™«è„šæœ¬è·å–æ•°æ®:")
            print("   python scrape_with_embeddings.py")
            raise FileNotFoundError(f"ç¼ºå°‘æ•°æ®æ–‡ä»¶: {', '.join(missing_files)}")
        
        print("âœ… æ‰€æœ‰å¿…è¦çš„æ•°æ®æ–‡ä»¶å·²æ‰¾åˆ°")
    
    def check_ollama_service(self):
        """æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€"""
        try:
            models = ollama.list()
            print(f"âœ… Ollama æœåŠ¡æ­£å¸¸ï¼Œå¯ç”¨æ¨¡å‹: {len(models['models'])} ä¸ª")
            
            model_names = [model['name'] for model in models['models']]
            if 'nomic-embed-text' not in model_names:
                print("âš ï¸  æœªæ‰¾åˆ° nomic-embed-text æ¨¡å‹ï¼Œæ­£åœ¨å®‰è£…...")
                ollama.pull('nomic-embed-text')
                print("âœ… nomic-embed-text æ¨¡å‹å®‰è£…å®Œæˆ")
            else:
                print("âœ… nomic-embed-text æ¨¡å‹å·²å®‰è£…")
                
        except Exception as e:
            print(f"âŒ Ollama æœåŠ¡æ£€æŸ¥å¤±è´¥: {str(e)}")
            raise
    
    def initialize_system(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–ä¼˜åŒ–é—®ç­”ç³»ç»Ÿ...")
        
        # åŠ è½½ FAISS ç´¢å¼•
        print("ğŸ” åŠ è½½ FAISS ç´¢å¼•...")
        self.faiss_index = faiss.read_index("./data_base/faiss_index.bin")
        print(f"âœ… FAISS ç´¢å¼•åŠ è½½å®Œæˆ: {self.faiss_index.ntotal} ä¸ªå‘é‡")
        
        # åŠ è½½å‘é‡å…ƒæ•°æ®
        print("ğŸ“Š åŠ è½½å‘é‡å…ƒæ•°æ®...")
        with open("./data_base/faiss_metadata.pkl", 'rb') as f:
            self.faiss_metadata = pickle.load(f)
        print(f"âœ… å…ƒæ•°æ®åŠ è½½å®Œæˆ: {len(self.faiss_metadata)} æ¡è®°å½•")
        
        # åŠ è½½ Wiki é¡µé¢æ•°æ®
        print("ğŸ“š åŠ è½½ Wiki é¡µé¢æ•°æ®...")
        with open("./data_base/seeed_wiki_embeddings_db.json", 'r', encoding='utf-8') as f:
            data = json.load(f)
            self.wiki_pages = data['pages']
            self.metadata = data['metadata']
        print(f"âœ… é¡µé¢æ•°æ®åŠ è½½å®Œæˆ: {len(self.wiki_pages)} ä¸ªé¡µé¢")
        
        # æµ‹è¯• Embedding æ¨¡å‹
        print("ğŸ¤– æµ‹è¯• Embedding æ¨¡å‹...")
        try:
            test_embedding = self.generate_embedding("test")
            if test_embedding is not None:
                print(f"âœ… Embedding æ¨¡å‹æµ‹è¯•æˆåŠŸ: {len(test_embedding)} ç»´")
            else:
                raise Exception("Embedding ç”Ÿæˆå¤±è´¥")
        except Exception as e:
            print(f"âŒ Embedding æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
            raise
        
        print("ğŸ‰ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
        self.show_system_info()
        
        # åŠ è½½ç¼“å­˜
        self.load_cache()
    
    def show_system_info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        print(f"\nğŸ“Š ç³»ç»Ÿä¿¡æ¯:")
        print(f"   æ€»é¡µé¢æ•°: {len(self.wiki_pages)}")
        print(f"   æ€»å‘é‡æ•°: {self.faiss_index.ntotal}")
        print(f"   å‘é‡ç»´åº¦: {self.metadata['vector_dimension']}")
        print(f"   å†…å®¹ç±»å‹: {self.metadata['content_type']}")
        print(f"   Embedding æ¨¡å‹: {self.metadata['embedding_model']}")
        print(f"   ç´¢å¼•ç±»å‹: {self.metadata['index_type']}")
        print(f"   çˆ¬å–æ—¶é—´: {self.metadata['crawl_time']}")
        print(f"   ç¼“å­˜çŠ¶æ€: Embeddingç¼“å­˜ {len(self.embedding_cache)} é¡¹ï¼Œå›ç­”ç¼“å­˜å·²ç¦ç”¨")
        print(f"   æµå¼æ˜¾ç¤º: {'å¯ç”¨' if self.streaming_enabled else 'ç¦ç”¨'}")
        print(f"   æ‰“å­—é€Ÿåº¦: {self.typing_speed:.3f} ç§’/å­—ç¬¦")
        print(f"   è¯­éŸ³åˆæˆ: {'å¯ç”¨' if self.tts_enabled else 'ç¦ç”¨'}")
        print(f"   è¯­éŸ³ç±»å‹: {self.tts_voice}")
        print(f"   è¯­éŸ³é€Ÿåº¦: {self.tts_speed:.1f}x")
        print(f"   éŸ³é¢‘æ ¼å¼: {self.tts_format}")
        print(f"   è¾“å‡ºç›®å½•: {self.tts_output_dir}")
        
        # æ˜¾ç¤ºéŸ³é¢‘æ–‡ä»¶ç»Ÿè®¡
        try:
            if os.path.exists(self.tts_output_dir):
                files = os.listdir(self.tts_output_dir)
                audio_files = [f for f in files if f.endswith(('.wav', '.mp3'))]
                total_size = sum(os.path.getsize(os.path.join(self.tts_output_dir, f)) 
                               for f in audio_files if os.path.isfile(os.path.join(self.tts_output_dir, f)))
                print(f"   éŸ³é¢‘æ–‡ä»¶: {len(audio_files)} ä¸ªï¼Œæ€»å¤§å°: {total_size} å­—èŠ‚")
            else:
                print(f"   éŸ³é¢‘æ–‡ä»¶: 0 ä¸ª")
        except Exception:
            print(f"   éŸ³é¢‘æ–‡ä»¶: æ— æ³•ç»Ÿè®¡")
    
    def load_cache(self):
        """åŠ è½½ç¼“å­˜æ•°æ®"""
        try:
            cache_file = "./data_base/cache_data.pkl"
            if os.path.exists(cache_file):
                with open(cache_file, 'rb') as f:
                    cache_data = pickle.load(f)
                    self.embedding_cache = cache_data.get('embedding_cache', {})
                    self.answer_cache = cache_data.get('answer_cache', {})
                print(f"âœ… ç¼“å­˜åŠ è½½å®Œæˆ: Embedding {len(self.embedding_cache)} é¡¹ï¼Œå›ç­” {len(self.answer_cache)} é¡¹")
        except Exception as e:
            print(f"âš ï¸  ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}")
    
    def save_cache(self):
        """ä¿å­˜ç¼“å­˜æ•°æ®"""
        try:
            cache_file = "./data_base/cache_data.pkl"
            cache_data = {
                'embedding_cache': self.embedding_cache,
                'answer_cache': self.answer_cache
            }
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            print(f"âœ… ç¼“å­˜ä¿å­˜å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸  ç¼“å­˜ä¿å­˜å¤±è´¥: {str(e)}")
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self.cache_lock:
            self.embedding_cache.clear()
            self.answer_cache.clear()
        print("âœ… ç¼“å­˜å·²æ¸…ç©º")
    
    def typewriter_effect(self, text, speed=None):
        """æ‰“å­—æœºæ•ˆæœæ˜¾ç¤ºæ–‡æœ¬"""
        if speed is None:
            speed = self.typing_speed
        
        for char in text:
            print(char, end='', flush=True)
            time.sleep(speed)
        print()  # æ¢è¡Œ
    
    def stream_response(self, response_generator):
        """æµå¼æ˜¾ç¤ºå›ç­”"""
        full_answer = ""
        print("ğŸ’¬ å›ç­”: ", end='', flush=True)
        
        try:
            for chunk in response_generator:
                if 'message' in chunk and 'content' in chunk['message']:
                    content = chunk['message']['content']
                    if content:
                        full_answer += content
                        print(content, end='', flush=True)
                        time.sleep(self.typing_speed)
        except Exception as e:
            print(f"\nâš ï¸  æµå¼æ˜¾ç¤ºé”™è¯¯: {str(e)}")
        
        print()  # æ¢è¡Œ
        return full_answer
    
    def text_to_speech(self, text, language="zh"):
        """æ–‡æœ¬è½¬è¯­éŸ³åŠŸèƒ½ï¼ˆä¿å­˜åˆ°æ–‡ä»¶ï¼‰"""
        if not self.tts_enabled:
            print("ğŸ”‡ TTSåŠŸèƒ½å·²ç¦ç”¨")
            return
        
        try:
            # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
            clean_text = re.sub(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘]', '', text)
            if len(clean_text.strip()) == 0:
                print("âš ï¸  æ–‡æœ¬å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡TTS")
                return
            
            print(f"ğŸ”Š æ­£åœ¨ç”Ÿæˆè¯­éŸ³æ–‡ä»¶...")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(self.tts_output_dir, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŸºäºæ—¶é—´æˆ³å’Œå†…å®¹å“ˆå¸Œï¼‰
            timestamp = int(time.time())
            text_hash = hashlib.md5(clean_text.encode('utf-8')).hexdigest()[:8]
            filename = f"tts_{timestamp}_{text_hash}.{self.tts_format}"
            filepath = os.path.join(self.tts_output_dir, filename)
            
            # ä½¿ç”¨espeakè¿›è¡ŒTTSå¹¶ä¿å­˜åˆ°æ–‡ä»¶
            if language == "zh":
                # ä¸­æ–‡è¯­éŸ³
                cmd = [
                    "espeak", 
                    "-v", "zh",  # ä¸­æ–‡è¯­éŸ³
                    "-s", str(int(150 * self.tts_speed)),  # è¯­é€Ÿ
                    "-a", "100",  # éŸ³é‡
                    "-w", filepath,  # è¾“å‡ºåˆ°æ–‡ä»¶
                    clean_text
                ]
            else:
                # è‹±æ–‡è¯­éŸ³
                cmd = [
                    "espeak", 
                    "-v", "en",  # è‹±æ–‡è¯­éŸ³
                    "-s", str(int(150 * self.tts_speed)),  # è¯­é€Ÿ
                    "-a", "100",  # éŸ³é‡
                    "-w", filepath,  # è¾“å‡ºåˆ°æ–‡ä»¶
                    clean_text
                ]
            
            # æ‰§è¡ŒTTS
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç”ŸæˆæˆåŠŸ
            if os.path.exists(filepath):
                file_size = os.path.getsize(filepath)
                if file_size > 0:
                    print(f"âœ… è¯­éŸ³æ–‡ä»¶ç”Ÿæˆå®Œæˆ: {filename}")
                    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {filepath}")
                    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                else:
                    print("âš ï¸  è¯­éŸ³æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼šæ–‡ä»¶å¤§å°ä¸º0")
            else:
                print("âš ï¸  è¯­éŸ³æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼šæ–‡ä»¶ä¸å­˜åœ¨")
            
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸  TTSç”Ÿæˆå¤±è´¥: {str(e)}")
            print(f"ğŸ“¤ è¿”å›ç : {e.returncode}")
            print(f"ğŸ“¤ æ ‡å‡†è¾“å‡º: {e.stdout}")
            print(f"âš ï¸  é”™è¯¯è¾“å‡º: {e.stderr}")
            print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…espeak: sudo apt-get install espeak")
        except FileNotFoundError:
            print("âš ï¸  æœªæ‰¾åˆ°espeakï¼Œè¯·å®‰è£…: sudo apt-get install espeak")
        except Exception as e:
            print(f"âš ï¸  TTSé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def check_tts_availability(self):
        """æ£€æŸ¥TTSå·¥å…·æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(["espeak", "--version"], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                print("âœ… TTSå·¥å…·(espeak)å¯ç”¨")
                return True
            else:
                print("âš ï¸  TTSå·¥å…·(espeak)ä¸å¯ç”¨")
                return False
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            print("âš ï¸  æœªå®‰è£…TTSå·¥å…·(espeak)")
            print("ğŸ’¡ å®‰è£…å‘½ä»¤: sudo apt-get install espeak")
            return False
    
    def list_audio_files(self):
        """åˆ—å‡ºéŸ³é¢‘è¾“å‡ºç›®å½•ä¸­çš„æ–‡ä»¶"""
        try:
            if not os.path.exists(self.tts_output_dir):
                print("ğŸ“ éŸ³é¢‘è¾“å‡ºç›®å½•ä¸å­˜åœ¨")
                return []
            
            files = os.listdir(self.tts_output_dir)
            audio_files = [f for f in files if f.endswith(('.wav', '.mp3'))]
            
            if not audio_files:
                print("ğŸ“ éŸ³é¢‘è¾“å‡ºç›®å½•ä¸ºç©º")
                return []
            
            print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨ ({len(audio_files)} ä¸ªæ–‡ä»¶):")
            for i, filename in enumerate(sorted(audio_files, reverse=True), 1):
                filepath = os.path.join(self.tts_output_dir, filename)
                file_size = os.path.getsize(filepath)
                file_time = time.ctime(os.path.getmtime(filepath))
                print(f"   {i}. {filename}")
                print(f"      å¤§å°: {file_size} å­—èŠ‚")
                print(f"      æ—¶é—´: {file_time}")
                print()
            
            return audio_files
            
        except Exception as e:
            print(f"âš ï¸  åˆ—å‡ºéŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    def clean_audio_files(self, keep_recent=10):
        """æ¸…ç†éŸ³é¢‘æ–‡ä»¶ï¼Œä¿ç•™æœ€è¿‘çš„Nä¸ªæ–‡ä»¶"""
        try:
            if not os.path.exists(self.tts_output_dir):
                return
            
            files = os.listdir(self.tts_output_dir)
            audio_files = [f for f in files if f.endswith(('.wav', '.mp3'))]
            
            if len(audio_files) <= keep_recent:
                print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶æ•°é‡({len(audio_files)})æœªè¶…è¿‡é™åˆ¶({keep_recent})ï¼Œæ— éœ€æ¸…ç†")
                return
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„æ–‡ä»¶
            audio_files_with_time = []
            for filename in audio_files:
                filepath = os.path.join(self.tts_output_dir, filename)
                mtime = os.path.getmtime(filepath)
                audio_files_with_time.append((filename, mtime))
            
            # æŒ‰æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
            audio_files_with_time.sort(key=lambda x: x[1], reverse=True)
            
            # åˆ é™¤æ—§æ–‡ä»¶
            files_to_delete = audio_files_with_time[keep_recent:]
            deleted_count = 0
            
            for filename, _ in files_to_delete:
                filepath = os.path.join(self.tts_output_dir, filename)
                try:
                    os.remove(filepath)
                    deleted_count += 1
                except Exception as e:
                    print(f"âš ï¸  åˆ é™¤æ–‡ä»¶ {filename} å¤±è´¥: {str(e)}")
            
            print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªæ—§éŸ³é¢‘æ–‡ä»¶")
            print(f"ğŸ“ ä¿ç•™äº†æœ€æ–°çš„ {keep_recent} ä¸ªéŸ³é¢‘æ–‡ä»¶")
            
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def generate_embedding(self, text):
        """ä½¿ç”¨ Ollama ç”Ÿæˆæ–‡æœ¬çš„ embedding å‘é‡ï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
        # ç”Ÿæˆæ–‡æœ¬çš„å“ˆå¸Œå€¼ä½œä¸ºç¼“å­˜é”®
        text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
        
        # æ£€æŸ¥ç¼“å­˜
        with self.cache_lock:
            if text_hash in self.embedding_cache:
                return self.embedding_cache[text_hash]
        
        try:
            response = ollama.embeddings(model=self.embedding_model, prompt=text)
            embedding = response["embedding"]
            embedding = np.array(embedding, dtype=np.float32)
            embedding = embedding / np.linalg.norm(embedding)
            
            # ç¼“å­˜ç»“æœ
            with self.cache_lock:
                self.embedding_cache[text_hash] = embedding
                # é™åˆ¶ç¼“å­˜å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º
                if len(self.embedding_cache) > 1000:
                    # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
                    oldest_key = next(iter(self.embedding_cache))
                    del self.embedding_cache[oldest_key]
            
            return embedding
        except Exception as e:
            print(f"âŒ Embedding ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def search_knowledge_base(self, query, top_k=20):
        """åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³å†…å®¹ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            query_embedding = self.generate_embedding(query)
            if query_embedding is None:
                return []
            
            query_embedding = query_embedding.reshape(1, -1).astype(np.float32)
            scores, indices = self.faiss_index.search(query_embedding, top_k)
            
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx < len(self.faiss_metadata):
                    metadata = self.faiss_metadata[idx]
                    page_data = self.wiki_pages[idx]
                    
                    results.append({
                        'rank': i + 1,
                        'score': float(score),
                        'title': metadata['title'],
                        'url': metadata['url'],
                        'content': page_data['content'],
                        'content_length': metadata['content_length'],
                        'timestamp': metadata['timestamp']
                    })
            
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            return []
    
    def ask_question(self, question):
        """æé—®å¹¶è·å–å›ç­”ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        print(f"\nğŸ¤” ç”¨æˆ·é—®é¢˜: {question}")
        
        # ç¦ç”¨å›ç­”ç¼“å­˜ï¼Œæ¯æ¬¡éƒ½å®æ—¶ç”Ÿæˆ
        # question_hash = hashlib.md5(question.encode('utf-8')).hexdigest()
        # with self.cache_lock:
        #     if question_hash in self.answer_cache:
        #         print("âš¡ ä½¿ç”¨ç¼“å­˜å›ç­”")
        #         print(f"\nğŸ’¬ å›ç­”:")
        #         print(f"{self.answer_cache[question_hash]}")
        #         return
        
        # æœç´¢çŸ¥è¯†åº“
        print("ğŸ” æ­£åœ¨æœç´¢çŸ¥è¯†åº“...")
        start_time = time.time()
        search_results = self.search_knowledge_base(question, top_k=20)  # å‡å°‘æœç´¢æ•°é‡
        search_time = time.time() - start_time
        
        if not search_results:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
            return
        
        print(f"âœ… æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.3f} ç§’")
        print(f"ğŸ“Š æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        # æ™ºèƒ½é€‰æ‹©æœ€ç›¸å…³çš„ç»“æœï¼ˆå‡å°‘åˆ°5ä¸ªï¼‰
        best_results = self.select_best_results(question, search_results, max_results=5)
        
        # æ˜¾ç¤ºæœç´¢ç»“æœ
        print(f"ğŸ” æœç´¢ç»“æœé¢„è§ˆ:")
        for i, result in enumerate(best_results[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  {i+1}. {result['title']}")
            print(f"     ç›¸å…³åº¦: {result['score']:.3f}")
            print(f"     URL: {result['url']}")
            print()
        
        # ç”Ÿæˆå›ç­”
        print("ğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")
        answer_start_time = time.time()
        answer = self.generate_answer(question, best_results)
        answer_time = time.time() - answer_start_time
        
        # æ˜¾ç¤ºå›ç­”
        print(f"\nğŸ’¬ å›ç­”:")
        print(f"{answer}")
        print(f"\nâ±ï¸  å›ç­”ç”Ÿæˆè€—æ—¶: {answer_time:.3f} ç§’")
        
        # æ–‡æœ¬è½¬è¯­éŸ³
        if self.tts_enabled:
            # æ£€æµ‹å›ç­”è¯­è¨€
            answer_language = self.detect_language(answer)
            self.text_to_speech(answer, answer_language)
        
        # ç¦ç”¨å›ç­”ç¼“å­˜ï¼Œä¸ä¿å­˜ç”Ÿæˆçš„å›ç­”
        # with self.cache_lock:
        #     self.answer_cache[question_hash] = answer
        #     # é™åˆ¶ç¼“å­˜å¤§å°
        #     if len(self.answer_cache) > 100:
        #         oldest_key = next(iter(self.answer_cache))
        #         del self.answer_cache[oldest_key]
    
    def select_best_results(self, question, search_results, max_results=10):
        """æ™ºèƒ½é€‰æ‹©æœ€ç›¸å…³çš„ç»“æœ"""
        if not search_results:
            return []
        
        # æå–é—®é¢˜ä¸­çš„å…³é”®è¯
        question_lower = question.lower()
        keywords = []
        
        # ä¸­æ–‡å…³é”®è¯
        chinese_keywords = ['çŸ½é€’', 'ç§‘æŠ€', 'å…¬å¸', 'ä»‹ç»', 'ç®€ä»‹', 'å…³äº', 'ä»€ä¹ˆæ˜¯', 'å¦‚ä½•', 'æ€ä¹ˆ']
        for keyword in chinese_keywords:
            if keyword in question_lower:
                keywords.append(keyword)
        
        # è‹±æ–‡å…³é”®è¯
        english_keywords = ['seeed', 'studio', 'company', 'introduction', 'about', 'what', 'how']
        for keyword in english_keywords:
            if keyword in question_lower:
                keywords.append(keyword)
        
        # è®¡ç®—æ¯ä¸ªç»“æœçš„ç›¸å…³æ€§åˆ†æ•°
        scored_results = []
        for result in search_results:
            score = result['score']
            title = result['title'].lower()
            content = result['content'].lower()
            
            # å…³é”®è¯åŒ¹é…åŠ åˆ†
            keyword_bonus = 0
            for keyword in keywords:
                if keyword in title:
                    keyword_bonus += 0.1
                if keyword in content:
                    keyword_bonus += 0.05
            
            # æ ‡é¢˜åŒ¹é…åŠ åˆ†
            title_bonus = 0
            if any(keyword in title for keyword in keywords):
                title_bonus += 0.05
            
            # è®¡ç®—æœ€ç»ˆåˆ†æ•°
            final_score = score + keyword_bonus + title_bonus
            scored_results.append((result, final_score))
        
        # æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº
        scored_results.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›å‰Nä¸ªæœ€ä½³ç»“æœ
        best_results = [result for result, score in scored_results[:max_results]]
        
        print(f"ğŸ” æ™ºèƒ½é€‰æ‹©ç»“æœ:")
        print(f"   å…³é”®è¯: {keywords}")
        print(f"   é€‰æ‹©ç»“æœæ•°: {len(best_results)}")
        
        return best_results

    def detect_language(self, text):
        """æ£€æµ‹æ–‡æœ¬è¯­è¨€ - æ”¹è¿›ç‰ˆæœ¬"""
        # æ£€æµ‹ä¸­æ–‡å­—ç¬¦
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
        english_chars = re.findall(r'[a-zA-Z]', text)
        
        # è®¡ç®—ä¸­è‹±æ–‡æ¯”ä¾‹
        total_chars = len(text.replace(' ', '').replace('\n', ''))
        if total_chars == 0:
            return 'en'  # é»˜è®¤ä¸ºè‹±æ–‡
            
        chinese_ratio = len(chinese_chars) / total_chars
        english_ratio = len(english_chars) / total_chars
        
        # å¦‚æœä¸­æ–‡å­—ç¬¦è¶…è¿‡20%ï¼Œæˆ–è€…ä¸­æ–‡æ¯”ä¾‹å¤§äºè‹±æ–‡æ¯”ä¾‹ï¼Œåˆ™è®¤ä¸ºæ˜¯ä¸­æ–‡
        if chinese_ratio > 0.1 or (chinese_ratio > 0 and chinese_ratio > english_ratio):
            return 'zh'
        elif english_ratio > 0.5:
            return 'en'
        else:
            # å¦‚æœéƒ½ä¸æ˜æ˜¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
            chinese_punctuation = re.findall(r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘]', text)
            if chinese_punctuation:
                return 'zh'
            return 'en'
    
    def generate_answer(self, question, search_results):
        """åŸºäºæœç´¢ç»“æœç”Ÿæˆå›ç­” - ä¼˜åŒ–ç‰ˆæœ¬"""
        if not search_results:
            return "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        
        # æ£€æµ‹ç”¨æˆ·é—®é¢˜çš„è¯­è¨€
        user_language = self.detect_language(question)
        print(f"ğŸ” æ£€æµ‹åˆ°é—®é¢˜è¯­è¨€: {user_language}")
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä¼˜åŒ–ï¼šé™åˆ¶é•¿åº¦ï¼‰
        context_parts = []
        total_length = 0
        max_context_length = 2000  # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
        
        for result in search_results:
            title = result['title']
            content = result['content']
            # ç§»é™¤ [Introduction] å‰ç¼€ï¼Œæ¸…ç†å†…å®¹
            if content.startswith('[Introduction] '):
                content = content[16:]
            
            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            if len(content) > 500:
                content = content[:500] + "..."
            
            context_part = f"æ–‡æ¡£æ ‡é¢˜: {title}\nå†…å®¹: {content}"
            
            # æ£€æŸ¥æ˜¯å¦ä¼šè¶…å‡ºé•¿åº¦é™åˆ¶
            if total_length + len(context_part) > max_context_length:
                break
                
            context_parts.append(context_part)
            total_length += len(context_part)
        
        context = "\n\n".join(context_parts)
        
        # æ ¹æ®ç”¨æˆ·è¯­è¨€é€‰æ‹© promptï¼Œå¼ºåˆ¶æŒ‡å®šè¾“å‡ºè¯­è¨€
        if user_language == 'zh':
            prompt = f"""è¯·åŸºäºä»¥ä¸‹èµ„æ–™ï¼Œç”¨è‡ªç„¶ã€è¿è´¯çš„ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é‡è¦è¦æ±‚ï¼š
1. å¿…é¡»ç”¨ä¸­æ–‡å›ç­”ï¼Œä¸èƒ½ä½¿ç”¨è‹±æ–‡
2. ä»‹ç»äº§å“æ—¶è¯´"æˆ‘ä»¬çš„xxxäº§å“..."
3. ä¸¥æ ¼åŸºäºæä¾›çš„èµ„æ–™å›ç­”ï¼Œç»å¯¹ä¸èƒ½ç¼–é€ æˆ–è™šæ„ä»»ä½•ä¿¡æ¯
4. å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰æŸä¸ªå…·ä½“ä¿¡æ¯ï¼ˆå¦‚æˆç«‹æ—¶é—´ã€å…·ä½“æ•°æ®ç­‰ï¼‰ï¼Œç»å¯¹ä¸è¦ç¼–é€ ï¼Œåº”è¯¥è¯´"èµ„æ–™ä¸­æœªæåŠ"
5. è¯­è¨€è¦æµç•…è‡ªç„¶ï¼Œä½“ç°ä¸“ä¸šä¸”äº²åˆ‡çš„ä¼ä¸šå½¢è±¡
6. ä¸è¦åˆ†ç‚¹åˆ†æ®µï¼Œç”¨ä¸€æ®µè¯æ¦‚æ‹¬æ‰€æœ‰ç›¸å…³ä¿¡æ¯
7. ä¸è¦é‡å¤è¯´"æˆ‘ä»¬æ˜¯Seeed Studioçš„AIåŠ©æ‰‹"è¿™æ ·çš„èº«ä»½ä»‹ç»

ç›¸å…³èµ„æ–™:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·ç”¨ä¸€æ®µè¿è´¯çš„ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨"æˆ‘ä»¬"çš„è¡¨è¾¾æ–¹å¼ï¼Œä¸¥æ ¼åŸºäºèµ„æ–™å†…å®¹ï¼Œä¸ç¼–é€ ä»»ä½•ä¿¡æ¯:"""
        else:
            prompt = f"""Please answer the user's question in natural, coherent English based on the following materials.

Important requirements:
1. Must answer in English, not in Chinese
2. Answer as Seeed Studio's representative, using "we" expressions
3. When introducing products, say "our xxx product..."
4. Strictly base your answer on the provided materials, absolutely do not fabricate or invent any information
5. If specific information (like founding date, specific data, etc.) is not mentioned in the materials, absolutely do not make it up, say "not mentioned in the materials"
6. Make the language fluent and natural, reflecting a professional yet friendly corporate image
7. Don't use bullet points or separate paragraphs, summarize all relevant information in one coherent paragraph
8. Don't repeat identity introductions like "We are Seeed Studio's AI assistant"

Materials:
{context}

User Question: {question}

Please answer using "we" expressions in one coherent English paragraph, strictly based on the materials without fabricating any information:"""
        
        # ä½¿ç”¨ Ollama ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰
        try:
            # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´å¿«çš„æ¨¡å‹å’Œæ›´ç®€æ´çš„prompt
            system_prompt = f'ç”¨{user_language}å›ç­”ï¼ŒåŸºäºèµ„æ–™ï¼Œä¸ç¼–é€ ä¿¡æ¯ï¼Œä¸è¦é‡å¤èº«ä»½ä»‹ç»ã€‚'
            
            if self.streaming_enabled:
                # æµå¼ç”Ÿæˆå›ç­”
                response_generator = ollama.chat(
                    model='qwen2.5:3b', 
                    messages=[
                        {'role': 'system', 'content': system_prompt},
                        {'role': 'user', 'content': prompt}
                    ],
                    options={
                        'temperature': 0.7,  # é™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
                        'top_p': 0.9,       # é™åˆ¶è¯æ±‡é€‰æ‹©èŒƒå›´
                        'num_predict': 300,  # é™åˆ¶ç”Ÿæˆé•¿åº¦
                    },
                    stream=True  # å¯ç”¨æµå¼è¾“å‡º
                )
                
                answer = self.stream_response(response_generator)
            else:
                # éæµå¼ç”Ÿæˆå›ç­”
                response = ollama.chat(
                    model='qwen2.5:3b', 
                    messages=[
                        {'role': 'system', 'content': system_prompt},
                        {'role': 'user', 'content': prompt}
                    ],
                    options={
                        'temperature': 0.7,
                        'top_p': 0.9,
                        'num_predict': 300,
                    }
                )
                
                answer = response['message']['content'].strip()
                # ä½¿ç”¨æ‰“å­—æœºæ•ˆæœæ˜¾ç¤º
                print("ğŸ’¬ å›ç­”: ", end='', flush=True)
                self.typewriter_effect(answer)
            
            # éªŒè¯å›ç­”è¯­è¨€
            answer_language = self.detect_language(answer)
            if answer_language != user_language:
                print(f"âš ï¸  AIå›ç­”è¯­è¨€ä¸åŒ¹é…ï¼ŒæœŸæœ›{user_language}ï¼Œå®é™…{answer_language}")
                answer = self.generate_manual_answer(question, search_results, user_language)
            
            # å¦‚æœå›ç­”å¤ªçŸ­ï¼Œæ·»åŠ ä¸€äº›è¡¥å……ä¿¡æ¯
            if len(answer) < 50:
                answer = self.generate_manual_answer(question, search_results, user_language)
            
            return answer
            
        except Exception as e:
            print(f"âš ï¸  AI ç”Ÿæˆå›ç­”å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {str(e)}")
            return self.generate_manual_answer(question, search_results, user_language)
    
    def generate_manual_answer(self, question, search_results, language='en'):
        """æ‰‹åŠ¨ç”Ÿæˆå›ç­”ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # æŒ‰ç›¸å…³åº¦æ’åº
        sorted_results = sorted(search_results, key=lambda x: x['score'], reverse=True)
        
        # æ ¹æ®é—®é¢˜ç±»å‹å’Œè¯­è¨€ç”Ÿæˆä¸åŒçš„å›ç­”
        question_lower = question.lower()
        
        if language == 'zh':
            # ä¸­æ–‡å›ç­”
            if "xiao" in question_lower or "å°" in question_lower:
                answer = "XIAOç³»åˆ—æ˜¯çŸ½é€’ç§‘æŠ€æ¨å‡ºçš„å¾®å‹å¼€å‘æ¿äº§å“çº¿ï¼Œè¿™äº›å¼€å‘æ¿è™½ç„¶ä½“ç§¯å°å·§ï¼Œä½†åŠŸèƒ½å´éå¸¸å¼ºå¤§ã€‚æˆ‘ä»¬é‡‡ç”¨äº†æ ‡å‡†åŒ–çš„è®¾è®¡ç†å¿µï¼Œå…·æœ‰å‡ºè‰²çš„å…¼å®¹æ€§å’Œæ‰©å±•æ€§ï¼Œç‰¹åˆ«é€‚åˆå„ç§åµŒå…¥å¼é¡¹ç›®ã€åŸå‹å¼€å‘å’Œåˆ›å®¢é¡¹ç›®ã€‚XIAOç³»åˆ—äº§å“ä¸ä»…æ”¯æŒArduinoç”Ÿæ€ç³»ç»Ÿï¼Œè¿˜é›†æˆäº†Groveè¿æ¥å™¨ï¼Œè®©æ‚¨å¯ä»¥è½»æ¾è¿æ¥å„ç§ä¼ æ„Ÿå™¨å’Œæ¨¡å—ï¼Œå¤§å¤§ç®€åŒ–äº†ç¡¬ä»¶å¼€å‘çš„å¤æ‚åº¦ã€‚"
            elif "grove" in question_lower:
                answer = "Groveä¼ æ„Ÿå™¨æ¨¡å—ç³»ç»Ÿæ˜¯çŸ½é€’ç§‘æŠ€å¼€å‘çš„ä¸€å¥—æ ‡å‡†åŒ–çš„ç¡¬ä»¶è¿æ¥è§£å†³æ–¹æ¡ˆï¼Œå®ƒå½»åº•æ”¹å˜äº†ä¼ ç»Ÿç¡¬ä»¶å¼€å‘çš„å¤æ‚æµç¨‹ã€‚é€šè¿‡ç»Ÿä¸€çš„è¿æ¥æ¥å£å’Œæ ‡å‡†åŒ–çš„æ¨¡å—è®¾è®¡ï¼ŒGroveç³»ç»Ÿè®©æ‚¨å¯ä»¥åƒæ­ç§¯æœ¨ä¸€æ ·è½»æ¾åœ°å°†å„ç§ä¼ æ„Ÿå™¨ã€æ‰§è¡Œå™¨å’Œé€šä¿¡æ¨¡å—è¿æ¥åˆ°å¼€å‘æ¿ä¸Šã€‚è¿™ç§è®¾è®¡ä¸ä»…å¤§å¤§é™ä½äº†ç¡¬ä»¶å¼€å‘çš„å…¥é—¨é—¨æ§›ï¼Œè¿˜æé«˜äº†é¡¹ç›®çš„å¯é æ€§å’Œå¯ç»´æŠ¤æ€§ï¼Œç‰¹åˆ«é€‚åˆåˆå­¦è€…å’Œå¿«é€ŸåŸå‹å¼€å‘ã€‚"
            elif "sensecap" in question_lower:
                answer = "SenseCAPæ˜¯çŸ½é€’ç§‘æŠ€ä¸“é—¨ä¸ºç¯å¢ƒç›‘æµ‹å’Œç‰©è”ç½‘åº”ç”¨æ‰“é€ çš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆï¼Œå®ƒé›†æˆäº†é«˜ç²¾åº¦çš„ä¼ æ„Ÿå™¨æŠ€æœ¯ã€å…ˆè¿›çš„æ•°æ®é‡‡é›†ç³»ç»Ÿå’Œå¼ºå¤§çš„äº‘ç«¯ç®¡ç†å¹³å°ã€‚è¿™å¥—ç³»ç»Ÿèƒ½å¤Ÿå®æ—¶ç›‘æµ‹å„ç§ç¯å¢ƒå‚æ•°ï¼Œå¦‚æ¸©åº¦ã€æ¹¿åº¦ã€ç©ºæ°”è´¨é‡ã€å…‰ç…§å¼ºåº¦ç­‰ï¼Œå¹¶å°†æ•°æ®é€šè¿‡æ— çº¿ç½‘ç»œä¼ è¾“åˆ°äº‘ç«¯è¿›è¡Œåˆ†æå’Œç®¡ç†ã€‚SenseCAPç‰¹åˆ«é€‚ç”¨äºæ™ºæ…§å†œä¸šã€ç¯å¢ƒç›‘æµ‹ã€å·¥ä¸šç‰©è”ç½‘ç­‰åœºæ™¯ï¼Œä¸ºç”¨æˆ·æä¾›å¯é ã€å‡†ç¡®çš„ç¯å¢ƒæ•°æ®æ”¯æŒã€‚"
            elif "edge computing" in question_lower or "è¾¹ç¼˜è®¡ç®—" in question_lower:
                answer = "è¾¹ç¼˜AIè®¡ç®—ä»£è¡¨äº†äººå·¥æ™ºèƒ½æŠ€æœ¯çš„ä¸€ä¸ªé‡è¦å‘å±•æ–¹å‘ï¼Œå®ƒå°†AIåº”ç”¨ä»äº‘ç«¯è¿ç§»åˆ°æœ¬åœ°è®¾å¤‡ä¸Šè¿è¡Œï¼Œå®ç°äº†æ›´å¿«çš„å“åº”é€Ÿåº¦å’Œæ›´å¥½çš„éšç§ä¿æŠ¤ã€‚é€šè¿‡reComputerç­‰åŸºäºNVIDIA Jetsonå¹³å°çš„è®¾å¤‡ï¼Œè¾¹ç¼˜è®¡ç®—èƒ½å¤Ÿåœ¨æœ¬åœ°å¤„ç†å„ç§AIä»»åŠ¡ï¼Œå¦‚è¯­éŸ³è¯†åˆ«ã€å›¾åƒå¤„ç†ã€è‡ªç„¶è¯­è¨€ç†è§£ç­‰ï¼Œè€Œæ— éœ€ä¾èµ–ç½‘ç»œè¿æ¥ã€‚è¿™ç§æŠ€æœ¯ç‰¹åˆ«é€‚åˆéœ€è¦å®æ—¶å¤„ç†ã€ä½å»¶è¿Ÿå“åº”çš„åº”ç”¨åœºæ™¯ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§ã€å·¥ä¸šè‡ªåŠ¨åŒ–ç­‰é¢†åŸŸã€‚"
            elif "recomputer" in question_lower:
                answer = "reComputerç³»åˆ—æ˜¯çŸ½é€’ç§‘æŠ€åŸºäºNVIDIA Jetsonå¹³å°å¼€å‘çš„é«˜æ€§èƒ½è¾¹ç¼˜è®¡ç®—è®¾å¤‡ï¼Œå®ƒä¸“é—¨ä¸ºAIå’Œè¾¹ç¼˜è®¡ç®—åº”ç”¨è€Œè®¾è®¡ã€‚è¿™äº›è®¾å¤‡é›†æˆäº†å¼ºå¤§çš„GPUè®¡ç®—èƒ½åŠ›ï¼Œæ”¯æŒå„ç§ä¸»æµçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå¦‚TensorFlowã€PyTorchç­‰ï¼Œèƒ½å¤Ÿè¿è¡Œå¤æ‚çš„AIæ¨¡å‹å’Œç®—æ³•ã€‚reComputerç³»åˆ—äº§å“ä¸ä»…æ€§èƒ½å¼ºåŠ²ï¼Œè¿˜å…·æœ‰è‰¯å¥½çš„æ•£çƒ­è®¾è®¡å’Œä¸°å¯Œçš„æ¥å£é…ç½®ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦æœ¬åœ°AIå¤„ç†èƒ½åŠ›çš„åº”ç”¨åœºæ™¯ï¼Œå¦‚æœºå™¨äººã€æ— äººæœºã€æ™ºèƒ½æ‘„åƒå¤´ç­‰ã€‚"
            else:
                answer = None
            
            if answer:
                # ä½¿ç”¨æ‰“å­—æœºæ•ˆæœæ˜¾ç¤º
                if self.streaming_enabled:
                    print("ğŸ’¬ å›ç­”: ", end='', flush=True)
                    self.typewriter_effect(answer)
                return answer
            
            else:
                # é€šç”¨ä¸­æ–‡å›ç­”
                top_result = sorted_results[0]
                title = top_result['title']
                content = top_result['content']
                score = top_result['score']
                
                if content.startswith('[Introduction] '):
                    content = content[16:]
                
                answer = f"æ ¹æ®æœç´¢ç»“æœï¼Œ{title} æä¾›äº†ä¸æ‚¨é—®é¢˜æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚{content[:300]}... è¿™ä¸ªç»“æœçš„ç›¸å…³åº¦è¯„åˆ†ä¸º {score:.3f}ï¼Œè¡¨æ˜å®ƒåŒ…å«äº†æ‚¨éœ€è¦çš„é‡è¦ä¿¡æ¯ã€‚å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„äº†è§£ï¼Œå¯ä»¥è®¿é—®ç›¸å…³çš„ Wiki é¡µé¢è·å–å®Œæ•´çš„æŠ€æœ¯è§„æ ¼å’Œä½¿ç”¨è¯´æ˜ã€‚"
                
                # ä½¿ç”¨æ‰“å­—æœºæ•ˆæœæ˜¾ç¤º
                if self.streaming_enabled:
                    print("ğŸ’¬ å›ç­”: ", end='', flush=True)
                    self.typewriter_effect(answer)
                
                return answer
        
        else:
            # è‹±æ–‡å›ç­”
            if "xiao" in question_lower:
                answer = "XIAO series is a line of micro development boards that we launched at Seeed Studio. These boards are compact in size but powerful in functionality, featuring our standardized design philosophy with excellent compatibility and expandability. They are particularly suitable for various embedded projects, prototyping, and maker projects. XIAO series products not only support the Arduino ecosystem but also integrate Grove connectors, allowing you to easily connect various sensors and modules, greatly simplifying the complexity of hardware development."
            elif "grove" in question_lower:
                answer = "Grove sensor module system is a standardized hardware connection solution that we developed at Seeed Studio, revolutionizing the complex process of traditional hardware development. Through unified connection interfaces and standardized module design, Grove system allows you to easily connect various sensors, actuators, and communication modules to development boards like building blocks. This design not only greatly reduces the entry barrier for hardware development but also improves project reliability and maintainability, making it particularly suitable for beginners and rapid prototyping."
            elif "sensecap" in question_lower:
                answer = "SenseCAP is a one-stop solution that we specifically designed at Seeed Studio for environmental monitoring and IoT applications. It integrates high-precision sensor technology, advanced data acquisition systems, and powerful cloud management platforms. The system can monitor various environmental parameters in real-time, such as temperature, humidity, air quality, light intensity, etc., and transmit data to the cloud for analysis and management through wireless networks. SenseCAP is particularly suitable for smart agriculture, environmental monitoring, industrial IoT, and other scenarios, providing users with reliable and accurate environmental data support."
            elif "edge computing" in question_lower:
                answer = "Edge AI computing represents an important development direction in artificial intelligence technology, moving AI applications from the cloud to local devices for operation, achieving faster response speeds and better privacy protection. Through devices like reComputer based on the NVIDIA Jetson platform, edge computing can process various AI tasks locally, such as speech recognition, image processing, natural language understanding, etc., without relying on network connections. This technology is particularly suitable for application scenarios that require real-time processing and low-latency responses, such as autonomous driving, intelligent monitoring, and industrial automation."
            elif "recomputer" in question_lower:
                answer = "reComputer series is a high-performance edge computing device that we developed at Seeed Studio based on the NVIDIA Jetson platform, specifically designed for AI and edge computing applications. These devices integrate powerful GPU computing capabilities and support various mainstream deep learning frameworks such as TensorFlow and PyTorch, enabling the operation of complex AI models and algorithms. reComputer series products are not only powerful in performance but also feature good thermal design and rich interface configurations, making them particularly suitable for application scenarios that require local AI processing capabilities, such as robotics, drones, and smart cameras."
            else:
                answer = None
            
            if answer:
                # ä½¿ç”¨æ‰“å­—æœºæ•ˆæœæ˜¾ç¤º
                if self.streaming_enabled:
                    print("ğŸ’¬ å›ç­”: ", end='', flush=True)
                    self.typewriter_effect(answer)
                return answer
            
            else:
                # é€šç”¨è‹±æ–‡å›ç­”
                top_result = sorted_results[0]
                title = top_result['title']
                content = top_result['content']
                score = top_result['score']
                
                if content.startswith('[Introduction] '):
                    content = content[16:]
                
                answer = f"Based on the search results, {title} provides the most relevant information for your question. {content[:300]}... This result has a relevance score of {score:.3f}, indicating that it contains important information you need. If you need more detailed information, you can visit the relevant Wiki page for complete technical specifications and usage instructions."
                
                # ä½¿ç”¨æ‰“å­—æœºæ•ˆæœæ˜¾ç¤º
                if self.streaming_enabled:
                    print("ğŸ’¬ å›ç­”: ", end='', flush=True)
                    self.typewriter_effect(answer)
                
                return answer
    
    def run(self):
        """è¿è¡Œé—®ç­”ç³»ç»Ÿ"""
        print("ğŸ¤– Seeed Studioï¼ˆçŸ½é€’ç§‘æŠ€ï¼‰ä¸“å±æ™ºèƒ½åŠ©æ‰‹")
        print("=" * 50)
        print("æ¬¢è¿ä½¿ç”¨æˆ‘ä»¬çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼")
        print("æˆ‘æ˜¯Seeed Studioçš„ä¸“å±AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡")
        print("=" * 50)
        
        sample_questions = [
            "ä»‹ç»ä¸€ä¸‹XIAOç³»åˆ—äº§å“",
            "Groveä¼ æ„Ÿå™¨æ¨¡å—æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
            "SenseCAPçš„åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
            "Edge Computingæ˜¯ä»€ä¹ˆï¼Ÿ",
            "reComputeræœ‰ä»€ä¹ˆç‰¹è‰²ï¼Ÿ"
        ]
        
        print(f"\nğŸ’¡ ç¤ºä¾‹é—®é¢˜:")
        for i, question in enumerate(sample_questions, 1):
            print(f"   {i}. {question}")
        
        print(f"\nğŸ’¬ ç°åœ¨å¯ä»¥å¼€å§‹æé—®äº†ï¼")
        print("ğŸ’¡ è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©ï¼Œ'quit' é€€å‡º")
        print("ğŸ’¡ æ”¯æŒæ–¹å‘é”®ã€é€€æ ¼é”®ç­‰ç¼–è¾‘åŠŸèƒ½")
        print("-" * 50)
        
        try:
            while True:
                try:
                    query = self.safe_input("\nğŸ¤” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ")
                    
                    if not query:
                        continue
                    
                    if query.lower() in ['quit', 'exit', 'q']:
                        print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                        break
                    elif query.lower() == 'help':
                        self.show_help()
                        continue
                    elif query.lower() == 'info':
                        self.show_system_info()
                        continue
                    elif query.lower() == 'sample':
                        print("ğŸ’¡ ç¤ºä¾‹é—®é¢˜:")
                        for i, question in enumerate(sample_questions, 1):
                            print(f"   {i}. {question}")
                        continue
                    elif query.lower() == 'clear':
                        self.clear_cache()
                        continue
                    elif query.lower() == 'save':
                        self.save_cache()
                        continue
                    elif query.lower() == 'stream':
                        self.streaming_enabled = not self.streaming_enabled
                        status = "å¯ç”¨" if self.streaming_enabled else "ç¦ç”¨"
                        print(f"âœ… æµå¼æ˜¾ç¤ºå·²{status}")
                        continue
                    elif query.lower() == 'speed':
                        print(f"å½“å‰æ‰“å­—é€Ÿåº¦: {self.typing_speed:.3f} ç§’/å­—ç¬¦")
                        try:
                            new_speed = float(self.safe_input("è¯·è¾“å…¥æ–°çš„æ‰“å­—é€Ÿåº¦ (0.01-0.1): "))
                            if 0.01 <= new_speed <= 0.1:
                                self.typing_speed = new_speed
                                print(f"âœ… æ‰“å­—é€Ÿåº¦å·²è®¾ç½®ä¸º: {new_speed:.3f} ç§’/å­—ç¬¦")
                            else:
                                print("âŒ é€Ÿåº¦èŒƒå›´åº”åœ¨ 0.01-0.1 ä¹‹é—´")
                        except ValueError:
                            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                        continue
                    elif query.lower() == 'tts':
                        self.tts_enabled = not self.tts_enabled
                        status = "å¯ç”¨" if self.tts_enabled else "ç¦ç”¨"
                        print(f"âœ… è¯­éŸ³åˆæˆå·²{status}")
                        continue
                    elif query.lower() == 'voice':
                        print(f"å½“å‰è¯­éŸ³ç±»å‹: {self.tts_voice}")
                        print("å¯ç”¨é€‰é¡¹: zh(ä¸­æ–‡), en(è‹±æ–‡)")
                        try:
                            new_voice = self.safe_input("è¯·è¾“å…¥æ–°çš„è¯­éŸ³ç±»å‹: ").lower()
                            if new_voice in ['zh', 'en']:
                                self.tts_voice = new_voice
                                print(f"âœ… è¯­éŸ³ç±»å‹å·²è®¾ç½®ä¸º: {new_voice}")
                            else:
                                print("âŒ è¯­éŸ³ç±»å‹åªèƒ½æ˜¯ zh æˆ– en")
                        except Exception as e:
                            print(f"âŒ è®¾ç½®å¤±è´¥: {str(e)}")
                        continue
                    elif query.lower() == 'ttsspeed':
                        print(f"å½“å‰è¯­éŸ³é€Ÿåº¦: {self.tts_speed:.1f}x")
                        try:
                            new_speed = float(self.safe_input("è¯·è¾“å…¥æ–°çš„è¯­éŸ³é€Ÿåº¦ (0.5-2.0): "))
                            if 0.5 <= new_speed <= 2.0:
                                self.tts_speed = new_speed
                                print(f"âœ… è¯­éŸ³é€Ÿåº¦å·²è®¾ç½®ä¸º: {new_speed:.1f}x")
                            else:
                                print("âŒ é€Ÿåº¦èŒƒå›´åº”åœ¨ 0.5-2.0 ä¹‹é—´")
                        except ValueError:
                            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                        continue
                    elif query.lower() == 'audio':
                        self.list_audio_files()
                        continue
                    elif query.lower() == 'clean':
                        try:
                            keep_count = int(self.safe_input("è¯·è¾“å…¥è¦ä¿ç•™çš„éŸ³é¢‘æ–‡ä»¶æ•°é‡ (é»˜è®¤10): ") or "10")
                            self.clean_audio_files(keep_count)
                        except ValueError:
                            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                        continue
                    elif query.lower() == 'format':
                        print(f"å½“å‰éŸ³é¢‘æ ¼å¼: {self.tts_format}")
                        print("å¯ç”¨æ ¼å¼: wav, mp3")
                        try:
                            new_format = self.safe_input("è¯·è¾“å…¥æ–°çš„éŸ³é¢‘æ ¼å¼: ").lower()
                            if new_format in ['wav', 'mp3']:
                                self.tts_format = new_format
                                print(f"âœ… éŸ³é¢‘æ ¼å¼å·²è®¾ç½®ä¸º: {new_format}")
                            else:
                                print("âŒ éŸ³é¢‘æ ¼å¼åªèƒ½æ˜¯ wav æˆ– mp3")
                        except Exception as e:
                            print(f"âŒ è®¾ç½®å¤±è´¥: {str(e)}")
                        continue
                    elif query.lower() == 'output':
                        print(f"å½“å‰è¾“å‡ºç›®å½•: {self.tts_output_dir}")
                        try:
                            new_dir = self.safe_input("è¯·è¾“å…¥æ–°çš„è¾“å‡ºç›®å½•: ").strip()
                            if new_dir:
                                self.tts_output_dir = new_dir
                                print(f"âœ… è¾“å‡ºç›®å½•å·²è®¾ç½®ä¸º: {new_dir}")
                            else:
                                print("âŒ è¾“å‡ºç›®å½•ä¸èƒ½ä¸ºç©º")
                        except Exception as e:
                            print(f"âŒ è®¾ç½®å¤±è´¥: {str(e)}")
                        continue
                    
                    if query.isdigit() and 1 <= int(query) <= len(sample_questions):
                        query = sample_questions[int(query) - 1]
                        print(f"ğŸ” é€‰æ‹©çš„é—®é¢˜: {query}")
                    
                    self.ask_question(query)
                    
                except KeyboardInterrupt:
                    print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
                    break
                except Exception as e:
                    print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
                    continue
                    
        finally:
            # ä¿å­˜è¾“å…¥å†å²å’Œç¼“å­˜
            self.save_history()
            self.save_cache()
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("   - ç›´æ¥è¾“å…¥é—®é¢˜")
        print("   - è¾“å…¥ 'help' æ˜¾ç¤ºå¸®åŠ©")
        print("   - è¾“å…¥ 'info' æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯")
        print("   - è¾“å…¥ 'sample' æ˜¾ç¤ºç¤ºä¾‹é—®é¢˜")
        print("   - è¾“å…¥ 'clear' æ¸…ç©ºç¼“å­˜")
        print("   - è¾“å…¥ 'save' ä¿å­˜ç¼“å­˜")
        print("   - è¾“å…¥ 'stream' åˆ‡æ¢æµå¼æ˜¾ç¤º")
        print("   - è¾“å…¥ 'speed' è°ƒæ•´æ‰“å­—é€Ÿåº¦")
        print("   - è¾“å…¥ 'tts' åˆ‡æ¢è¯­éŸ³åˆæˆ")
        print("   - è¾“å…¥ 'voice' è®¾ç½®è¯­éŸ³ç±»å‹")
        print("   - è¾“å…¥ 'ttsspeed' è°ƒæ•´è¯­éŸ³é€Ÿåº¦")
        print("   - è¾“å…¥ 'format' è®¾ç½®éŸ³é¢‘æ ¼å¼")
        print("   - è¾“å…¥ 'output' è®¾ç½®è¾“å‡ºç›®å½•")
        print("   - è¾“å…¥ 'audio' åˆ—å‡ºéŸ³é¢‘æ–‡ä»¶")
        print("   - è¾“å…¥ 'clean' æ¸…ç†æ—§éŸ³é¢‘æ–‡ä»¶")
        print("   - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç¨‹åº")
        print("\nâŒ¨ï¸  è¾“å…¥åŠŸèƒ½:")
        print("   - æ”¯æŒæ–¹å‘é”®ç§»åŠ¨å…‰æ ‡")
        print("   - æ”¯æŒé€€æ ¼é”®åˆ é™¤å­—ç¬¦")
        print("   - æ”¯æŒ Ctrl+A é€‰æ‹©å…¨éƒ¨")
        print("   - æ”¯æŒ Ctrl+U åˆ é™¤æ•´è¡Œ")
        print("   - æ”¯æŒ Tab é”®è‡ªåŠ¨è¡¥å…¨")
        print("\nğŸš€ ç³»ç»Ÿç‰¹æ€§:")
        print("   - ä½¿ç”¨é¢„ä¿å­˜çš„ FAISS ç´¢å¼•ï¼Œå¯åŠ¨å¿«é€Ÿ")
        print("   - åŸºäº Ollama nomic-embed-text æ¨¡å‹")
        print("   - æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œé‡å¤é—®é¢˜ç§’ç­”")
        print("   - ä¼˜åŒ–çš„æœç´¢ç®—æ³•ï¼Œå“åº”æ›´å¿«")
        print("   - æµå¼å›ç­”æ˜¾ç¤ºï¼Œæ‰“å­—æœºæ•ˆæœ")
        print("   - æ–‡æœ¬è½¬è¯­éŸ³åŠŸèƒ½ï¼Œä¿å­˜ä¸ºéŸ³é¢‘æ–‡ä»¶")
        print("   - æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼å’Œæ–‡ä»¶ç®¡ç†")
        print("   - å®æ—¶ç”Ÿæˆå›ç­”ï¼Œä¸ä¿å­˜ç¼“å­˜")
        print("   - åŸºäºè‹±æ–‡ Wiki å†…å®¹ï¼Œè´¨é‡é«˜")

def main():
    """ä¸»å‡½æ•°"""
    try:
        qa_system = OptimizedQASystem()
        qa_system.run()
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’Œ Ollama æœåŠ¡")

if __name__ == "__main__":
    main()

