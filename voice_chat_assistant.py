#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯­éŸ³å¯¹è¯åŠ©æ‰‹
é›†æˆKokoro TTSå’Œé—®ç­”ç³»ç»Ÿï¼Œå®ç°å®æ—¶è¯­éŸ³å¯¹è¯
æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼Œä¼˜åŒ–æ¨ç†é€Ÿåº¦
"""

import json
import os
import pickle
import numpy as np
import faiss
import ollama
import time
import re
import sys
import readline
import hashlib
import threading
import queue
import torch
import gc
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor
import pygame
from kokoro import KPipeline
import numpy as np


class VoiceChatAssistant:
    def __init__(self):
        # åŸºç¡€é—®ç­”ç³»ç»Ÿç»„ä»¶
        self.faiss_index = None
        self.faiss_metadata = None
        self.wiki_pages = []
        self.embedding_model = "nomic-embed-text"
        
        # ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–
        self.embedding_cache = {}
        self.cache_lock = threading.Lock()
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # æµå¼æ˜¾ç¤ºç›¸å…³
        self.streaming_enabled = True
        self.typing_speed = 0.02
        
        # TTSç›¸å…³
        self.tts_pipeline_zh = None  # ä¸­æ–‡TTSæ¨¡å‹
        self.tts_pipeline_en = None  # è‹±æ–‡TTSæ¨¡å‹
        self.tts_device = None
        self.tts_available = False
        self.audio_playing = False
        
        # å¤šçº¿ç¨‹å¤„ç†
        self.llm_thread = None
        self.tts_thread = None
        self.audio_thread = None
        
        # ä»»åŠ¡é˜Ÿåˆ—
        self.llm_queue = queue.Queue()
        self.tts_queue = queue.Queue()
        self.audio_queue = queue.Queue()
        
        # æ§åˆ¶æ ‡å¿—
        self.running = False
        self.llm_processing = False
        self.tts_processing = False
        self.audio_processing = False
        
        # éŸ³é¢‘ç³»ç»Ÿ
        self.audio_initialized = False
        
        # è®¾ç½®readline
        self.setup_readline()
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        self.initialize_system()
    
    def setup_readline(self):
        """è®¾ç½®readlineé…ç½®"""
        try:
            histfile = os.path.join(os.path.expanduser("~"), ".voice_chat_history")
            readline.read_history_file(histfile)
            readline.set_history_length(1000)
            readline.parse_and_bind('tab: complete')
            readline.parse_and_bind('set editing-mode emacs')
        except Exception as e:
            print(f"âš ï¸ readlineè®¾ç½®å¤±è´¥: {str(e)}")
    
    def safe_input(self, prompt):
        """å®‰å…¨çš„è¾“å…¥å‡½æ•°"""
        try:
            user_input = input(prompt)
            return user_input.strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
            sys.exit(0)
        except Exception as e:
            print(f"\nâŒ è¾“å…¥é”™è¯¯: {str(e)}")
            return ""
    
    def check_data_files(self):
        """æ£€æŸ¥å¿…è¦çš„æ•°æ®æ–‡ä»¶"""
        required_files = [
            "./data_base/faiss_index.bin",
            "./data_base/faiss_metadata.pkl",
            "./data_base/seeed_wiki_embeddings_db.json"
        ]
        
        missing_files = []
        for file in required_files:
            if not os.path.exists(file):
                missing_files.append(file)
        
        if missing_files:
            print("âŒ ç¼ºå°‘å¿…è¦çš„æ•°æ®æ–‡ä»¶:")
            for file in missing_files:
                print(f"   - {file}")
            print("\nğŸ’¡ è¯·å…ˆè¿è¡Œçˆ¬è™«è„šæœ¬è·å–æ•°æ®:")
            print("   python scrape_with_embeddings.py")
            raise FileNotFoundError(f"ç¼ºå°‘æ•°æ®æ–‡ä»¶: {', '.join(missing_files)}")
        
        print("âœ… æ‰€æœ‰å¿…è¦çš„æ•°æ®æ–‡ä»¶å·²æ‰¾åˆ°")
    
    def check_ollama_service(self):
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        try:
            models = ollama.list()
            print(f"âœ… OllamaæœåŠ¡æ­£å¸¸ï¼Œå¯ç”¨æ¨¡å‹: {len(models.models)} ä¸ª")
            
            model_names = [model.model for model in models.models]
            if 'nomic-embed-text:latest' not in model_names:
                print("âš ï¸ æœªæ‰¾åˆ°nomic-embed-textæ¨¡å‹ï¼Œæ­£åœ¨å®‰è£…...")
                ollama.pull('nomic-embed-text')
                print("âœ… nomic-embed-textæ¨¡å‹å®‰è£…å®Œæˆ")
            else:
                print("âœ… nomic-embed-textæ¨¡å‹å·²å®‰è£…")
                
        except Exception as e:
            print(f"âŒ OllamaæœåŠ¡æ£€æŸ¥å¤±è´¥: {str(e)}")
            raise
    
    def initialize_tts(self):
        """åˆå§‹åŒ–TTSç³»ç»Ÿ"""
        try:
            print("ğŸ¤ åˆå§‹åŒ–Kokoro TTSç³»ç»Ÿ...")
            
            # æ£€æŸ¥GPUå¯ç”¨æ€§
            self.tts_device = 'cuda' if torch.cuda.is_available() else 'cpu'
            print(f"ğŸ¤ ä½¿ç”¨è®¾å¤‡: {self.tts_device}")
            
            # åˆå§‹åŒ–pygameéŸ³é¢‘ç³»ç»Ÿï¼Œå¢åŠ ç¼“å†²åŒºå¤§å°ä»¥æ”¯æŒé•¿éŸ³é¢‘
            pygame.mixer.init(frequency=24000, size=-16, channels=1, buffer=4096)
            self.audio_initialized = True
            print("âœ… pygameéŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ (ç¼“å†²åŒº: 4096)")
            
            # åŠ è½½éŸ³è‰²æ–‡ä»¶
            print("ğŸµ åŠ è½½éŸ³è‰²æ–‡ä»¶...")
            voice_zf = "zf_001"
            voice_af = 'af_heart'
            voice_zf_path = f'ckpts/kokoro-v1.1/voices/{voice_zf}.pt'
            voice_af_path = f'ckpts/kokoro-v1.1/voices/{voice_af}.pt'
            
            if os.path.exists(voice_zf_path):
                self.voice_zf_tensor = torch.load(voice_zf_path, weights_only=True)
                print(f"âœ… åŠ è½½ä¸­æ–‡éŸ³è‰²: {voice_zf}")
            else:
                print(f"âŒ ä¸­æ–‡éŸ³è‰²æ–‡ä»¶ä¸å­˜åœ¨: {voice_zf_path}")
                self.voice_zf_tensor = None
            
            if os.path.exists(voice_af_path):
                self.voice_af_tensor = torch.load(voice_af_path, weights_only=True)
                print(f"âœ… åŠ è½½è‹±æ–‡éŸ³è‰²: {voice_af}")
            else:
                print(f"âŒ è‹±æ–‡éŸ³è‰²æ–‡ä»¶ä¸å­˜åœ¨: {voice_af_path}")
                self.voice_af_tensor = None
            
            # åˆå§‹åŒ–è‹±æ–‡TTSæ¨¡å‹ï¼ˆç”¨äºen_callableï¼‰
            print("ğŸ”§ åŠ è½½è‹±æ–‡Kokoro TTSæ¨¡å‹...")
            start_time = time.time()
            self.tts_pipeline_en = KPipeline(lang_code='a', device=self.tts_device)
            en_load_time = time.time() - start_time
            print(f"âœ… è‹±æ–‡TTSæ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {en_load_time:.2f}ç§’")
            
            # å®šä¹‰è‹±æ–‡å›è°ƒå‡½æ•°ï¼Œç”¨äºå¤„ç†ä¸­è‹±æ··æ‚æ–‡æœ¬ä¸­çš„è‹±æ–‡éƒ¨åˆ†
            def en_callable(text):
                """
                è‹±æ–‡å›è°ƒå‡½æ•°ï¼Œå¤„ç†ä¸­è‹±æ··æ‚æ–‡æœ¬ä¸­çš„è‹±æ–‡éƒ¨åˆ†
                è¿”å›è‹±æ–‡æ–‡æœ¬çš„éŸ³ç´ è¡¨ç¤º
                """
                print(f"    ğŸ¤ å¤„ç†è‹±æ–‡æ–‡æœ¬: '{text}'")
                
                # ç‰¹æ®Šè¯æ±‡çš„éŸ³ç´ æ˜ å°„
                if text == 'Kokoro':
                    return 'kËˆOkÉ™É¹O'
                elif text == 'Sol':
                    return 'sËˆOl'
                elif text == 'reComputer':
                    return 'riËkÉ™mËˆpjuËtÉ™r'
                elif text == 'Jetson':
                    return 'ËˆdÊ’É›tsÉ™n'
                elif text == 'Hello':
                    return 'hÉ™ËˆloÊŠ'
                elif text == 'world':
                    return 'wÉœËrld'
                elif text == 'Welcome':
                    return 'ËˆwelkÉ™m'
                elif text == 'to':
                    return 'tuË'
                elif text == 'TTS':
                    return 'tiËtiËËˆes'
                elif text == 'AI':
                    return 'eÉªËˆaÉª'
                elif text == 'technology':
                    return 'tekËˆnÉ‘ËlÉ™dÊ’i'
                elif text == 'is':
                    return 'Éªz'
                elif text == 'advancing':
                    return 'É™dËˆvÃ¦nsÉªÅ‹'
                elif text == 'rapidly':
                    return 'ËˆrÃ¦pÉ™dli'
                elif text == 'It\'s':
                    return 'Éªts'
                elif text == 'a':
                    return 'É™'
                elif text == 'beautiful':
                    return 'ËˆbjuËtÉªfÉ™l'
                elif text == 'day':
                    return 'deÉª'
                elif text == 'today':
                    return 'tÉ™ËˆdeÉª'
                elif text == 'Seeed':
                    return 'siËd'
                elif text == 'Studio':
                    return 'ËˆstuËdioÊŠ'
                elif text == 'XIAO':
                    return 'ËˆÊƒaÊŠ'
                elif text == 'Grove':
                    return 'É¡roÊŠv'
                elif text == 'SenseCAP':
                    return 'ËˆsenskÃ¦p'
                elif text == 'Edge':
                    return 'edÊ’'
                elif text == 'Computing':
                    return 'kÉ™mËˆpjuËtÉªÅ‹'
                
                # å¯¹äºå…¶ä»–è‹±æ–‡è¯æ±‡ï¼Œä½¿ç”¨è‹±æ–‡ç®¡é“ç”ŸæˆéŸ³ç´ 
                try:
                    selected_voice = self.voice_af_tensor if self.voice_af_tensor is not None else self.voice_zf_tensor
                    result = next(self.tts_pipeline_en(text, voice=selected_voice))
                    return result.phonemes
                except Exception as e:
                    print(f"    âš ï¸ æ— æ³•å¤„ç†è‹±æ–‡æ–‡æœ¬ '{text}': {e}")
                    # è¿”å›åŸå§‹æ–‡æœ¬ä½œä¸ºfallback
                    return text
            
            # åˆå§‹åŒ–ä¸­æ–‡TTSæ¨¡å‹ï¼ˆæ”¯æŒä¸­è‹±æ··åˆï¼‰
            print("ğŸ”§ åŠ è½½ä¸­æ–‡Kokoro TTSæ¨¡å‹ï¼ˆæ”¯æŒä¸­è‹±æ··åˆï¼‰...")
            start_time = time.time()
            self.tts_pipeline_zh = KPipeline(lang_code='z', device=self.tts_device, en_callable=en_callable)
            zh_load_time = time.time() - start_time
            print(f"âœ… ä¸­æ–‡TTSæ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {zh_load_time:.2f}ç§’")
            
            # æ¨¡å‹é¢„çƒ­
            print("ğŸ”¥ è¿›è¡ŒTTSæ¨¡å‹é¢„çƒ­...")
            warmup_start = time.time()
            
            # é¢„çƒ­ä¸­æ–‡æ¨¡å‹ï¼ˆä½¿ç”¨ä¸­æ–‡éŸ³è‰²ï¼‰
            warmup_text_zh = "ä½ å¥½"
            zh_voice = self.voice_zf_tensor if self.voice_zf_tensor is not None else 'af_heart'
            generator_zh = self.tts_pipeline_zh(warmup_text_zh, voice=zh_voice)
            for gs, ps, audio in generator_zh:
                if isinstance(audio, torch.Tensor):
                    audio = audio.detach().cpu().numpy()
                break
            
            # é¢„çƒ­è‹±æ–‡æ¨¡å‹ï¼ˆä½¿ç”¨è‹±æ–‡éŸ³è‰²ï¼‰
            warmup_text_en = "Hello"
            en_voice = self.voice_af_tensor if self.voice_af_tensor is not None else 'af_heart'
            generator_en = self.tts_pipeline_en(warmup_text_en, voice=en_voice)
            for gs, ps, audio in generator_en:
                if isinstance(audio, torch.Tensor):
                    audio = audio.detach().cpu().numpy()
                break
            
            warmup_time = time.time() - warmup_start
            print(f"âœ… TTSé¢„çƒ­å®Œæˆï¼Œè€—æ—¶: {warmup_time:.2f}ç§’")
            
            self.tts_available = True
            print("ğŸ‰ åŒè¯­è¨€TTSç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ TTSåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.tts_available = False
            raise
    
    def initialize_system(self):
        """åˆå§‹åŒ–æ•´ä¸ªç³»ç»Ÿ"""
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³å¯¹è¯åŠ©æ‰‹...")
        
        try:
            # æ£€æŸ¥æ•°æ®æ–‡ä»¶
            self.check_data_files()
            
            # æ£€æŸ¥OllamaæœåŠ¡
            self.check_ollama_service()
            
            # åŠ è½½FAISSç´¢å¼•
            print("ğŸ” åŠ è½½FAISSç´¢å¼•...")
            self.faiss_index = faiss.read_index("./data_base/faiss_index.bin")
            print(f"âœ… FAISSç´¢å¼•åŠ è½½å®Œæˆ: {self.faiss_index.ntotal} ä¸ªå‘é‡")
            
            # åŠ è½½å…ƒæ•°æ®
            print("ğŸ“Š åŠ è½½å…ƒæ•°æ®...")
            with open("./data_base/faiss_metadata.pkl", 'rb') as f:
                self.faiss_metadata = pickle.load(f)
            print(f"âœ… å…ƒæ•°æ®åŠ è½½å®Œæˆ: {len(self.faiss_metadata)} æ¡è®°å½•")
            
            # åŠ è½½Wikié¡µé¢æ•°æ®
            print("ğŸ“š åŠ è½½Wikié¡µé¢æ•°æ®...")
            with open("./data_base/seeed_wiki_embeddings_db.json", 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.wiki_pages = data['pages']
                self.metadata = data['metadata']
            print(f"âœ… é¡µé¢æ•°æ®åŠ è½½å®Œæˆ: {len(self.wiki_pages)} ä¸ªé¡µé¢")
            
            # åˆå§‹åŒ–TTSç³»ç»Ÿ
            self.initialize_tts()
            
            # å¯åŠ¨å·¥ä½œçº¿ç¨‹
            self.start_worker_threads()
            
            print("ğŸ‰ è¯­éŸ³å¯¹è¯åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆï¼")
            self.show_system_info()
            
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            raise
    
    def start_worker_threads(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹"""
        print("ğŸ§µ å¯åŠ¨å·¥ä½œçº¿ç¨‹...")
        
        self.running = True
        
        # å¯åŠ¨LLMå¤„ç†çº¿ç¨‹
        self.llm_thread = threading.Thread(target=self.llm_worker, daemon=True)
        self.llm_thread.start()
        print("âœ… LLMå¤„ç†çº¿ç¨‹å·²å¯åŠ¨")
        
        # å¯åŠ¨TTSå¤„ç†çº¿ç¨‹
        self.tts_thread = threading.Thread(target=self.tts_worker, daemon=True)
        self.tts_thread.start()
        print("âœ… TTSå¤„ç†çº¿ç¨‹å·²å¯åŠ¨")
        
        # å¯åŠ¨éŸ³é¢‘æ’­æ”¾çº¿ç¨‹
        self.audio_thread = threading.Thread(target=self.audio_worker, daemon=True)
        self.audio_thread.start()
        print("âœ… éŸ³é¢‘æ’­æ”¾çº¿ç¨‹å·²å¯åŠ¨")
    
    def llm_worker(self):
        """LLMå¤„ç†å·¥ä½œçº¿ç¨‹"""
        while self.running:
            try:
                # ç­‰å¾…ä»»åŠ¡
                if self.llm_queue.empty():
                    time.sleep(0.1)
                    continue
                
                # è·å–ä»»åŠ¡
                task = self.llm_queue.get(timeout=1)
                self.llm_processing = True
                
                # å¤„ç†ä»»åŠ¡
                question = task['question']
                callback = task['callback']
                
                print(f"ğŸ¤– [LLMçº¿ç¨‹] å¼€å§‹å¤„ç†é—®é¢˜: '{question[:30]}...'")
                start_time = time.time()
                
                # ç”Ÿæˆå›ç­”
                answer = self.generate_answer(question)
                
                process_time = time.time() - start_time
                print(f"âœ… [LLMçº¿ç¨‹] å›ç­”ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {process_time:.2f}ç§’")
                
                # å›è°ƒå¤„ç†
                if callback:
                    callback(answer)
                
                self.llm_processing = False
                self.llm_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ [LLMçº¿ç¨‹] å¤„ç†é”™è¯¯: {str(e)}")
                self.llm_processing = False
                time.sleep(1)
    
    def tts_worker(self):
        """TTSå¤„ç†å·¥ä½œçº¿ç¨‹"""
        while self.running:
            try:
                # ç­‰å¾…ä»»åŠ¡
                if self.tts_queue.empty():
                    time.sleep(0.1)
                    continue
                
                # è·å–ä»»åŠ¡
                task = self.tts_queue.get(timeout=1)
                self.tts_processing = True
                
                # å¤„ç†ä»»åŠ¡
                text = task['text']
                callback = task['callback']
                
                if not self.tts_available or not text.strip():
                    self.tts_processing = False
                    self.tts_queue.task_done()
                    continue
                
                # æ£€æµ‹è¯­è¨€
                language = self.detect_language(text)
                print(f"ğŸ¤ [TTSçº¿ç¨‹] å¼€å§‹ç”Ÿæˆè¯­éŸ³: '{text[:30]}...' (è¯­è¨€: {language})")
                start_time = time.time()
                
                # æ ¹æ®è¯­è¨€é€‰æ‹©TTSæ¨¡å‹å’ŒéŸ³è‰²
                if language == 'zh':
                    pipeline = self.tts_pipeline_zh
                    # ä½¿ç”¨ä¸­æ–‡éŸ³è‰²ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨è‹±æ–‡éŸ³è‰²
                    selected_voice = self.voice_zf_tensor if self.voice_zf_tensor is not None else self.voice_af_tensor
                    if selected_voice is None:
                        selected_voice = 'af_heart'
                else:
                    pipeline = self.tts_pipeline_en
                    # ä½¿ç”¨è‹±æ–‡éŸ³è‰²ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ä¸­æ–‡éŸ³è‰²
                    selected_voice = self.voice_af_tensor if self.voice_af_tensor is not None else self.voice_zf_tensor
                    if selected_voice is None:
                        selected_voice = 'af_heart'
                
                # ç”Ÿæˆè¯­éŸ³
                audio_segments = []
                generator = pipeline(text, voice=selected_voice)
                
                segment_count = 0
                for gs, ps, audio in generator:
                    if isinstance(audio, torch.Tensor):
                        audio = audio.detach().cpu().numpy()
                    
                    # éŸ³é¢‘é¢„å¤„ç†
                    if audio.dtype != np.float32:
                        audio = audio.astype(np.float32)
                    
                    # å½’ä¸€åŒ–
                    max_val = np.max(np.abs(audio))
                    if max_val > 1.0:
                        audio = audio / max_val
                    
                    # è½¬æ¢ä¸ºint16æ ¼å¼
                    audio_int16 = (audio * 32767).astype(np.int16)
                    audio_segments.append(audio_int16)
                    segment_count += 1
                    print(f"    ğŸ“ å¤„ç†éŸ³é¢‘ç‰‡æ®µ {segment_count} (é•¿åº¦: {len(audio_int16)/24000:.1f}ç§’)")
                
                process_time = time.time() - start_time
                print(f"âœ… [TTSçº¿ç¨‹] è¯­éŸ³ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {process_time:.2f}ç§’")
                
                # å°†éŸ³é¢‘ç‰‡æ®µåŠ å…¥æ’­æ”¾é˜Ÿåˆ—
                for segment in audio_segments:
                    self.audio_queue.put(segment)
                
                # å›è°ƒå¤„ç†
                if callback:
                    callback(len(audio_segments))
                
                self.tts_processing = False
                self.tts_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ [TTSçº¿ç¨‹] å¤„ç†é”™è¯¯: {str(e)}")
                self.tts_processing = False
                time.sleep(1)
    
    def audio_worker(self):
        """éŸ³é¢‘æ’­æ”¾å·¥ä½œçº¿ç¨‹"""
        while self.running:
            try:
                # ç­‰å¾…éŸ³é¢‘ç‰‡æ®µ
                if self.audio_queue.empty():
                    time.sleep(0.01)
                    continue
                
                # è·å–éŸ³é¢‘ç‰‡æ®µ
                audio_segment = self.audio_queue.get(timeout=0.1)
                self.audio_processing = True
                
                # æ’­æ”¾éŸ³é¢‘
                try:
                    # è®¡ç®—éŸ³é¢‘é•¿åº¦
                    audio_duration = len(audio_segment) / 24000.0
                    print(f"ğŸ”Š [éŸ³é¢‘çº¿ç¨‹] å¼€å§‹æ’­æ”¾éŸ³é¢‘ç‰‡æ®µ (é•¿åº¦: {audio_duration:.1f}ç§’)")
                    
                    sound = pygame.sndarray.make_sound(audio_segment)
                    sound.play()
                    
                    # ç­‰å¾…æ’­æ”¾å®Œæˆï¼Œä½¿ç”¨æ›´ä¿å®ˆçš„è¶…æ—¶æœºåˆ¶
                    start_time = time.time()
                    # è¶…æ—¶æ—¶é—´è®¾ä¸ºéŸ³é¢‘é•¿åº¦çš„3å€ï¼Œä½†æœ€å°‘30ç§’ï¼Œæœ€å¤š120ç§’
                    max_wait_time = max(30.0, min(120.0, audio_duration * 3))
                    
                    print(f"ğŸ”Š [éŸ³é¢‘çº¿ç¨‹] é¢„è®¡æ’­æ”¾æ—¶é—´: {audio_duration:.1f}ç§’ï¼Œæœ€å¤§ç­‰å¾…: {max_wait_time:.1f}ç§’")
                    
                    # ä½¿ç”¨æ›´å¯é çš„æ’­æ”¾æ£€æµ‹
                    last_busy_time = time.time()
                    while True:
                        is_busy = pygame.mixer.get_busy()
                        current_time = time.time()
                        elapsed_time = current_time - start_time
                        
                        if not is_busy:
                            # å¦‚æœä¸å†å¿™ç¢Œï¼Œç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®è®¤æ’­æ”¾å®Œæˆ
                            if current_time - last_busy_time > 0.5:  # ç­‰å¾…0.5ç§’ç¡®è®¤
                                break
                        else:
                            last_busy_time = current_time
                        
                        if elapsed_time > max_wait_time:
                            print(f"âš ï¸ [éŸ³é¢‘çº¿ç¨‹] æ’­æ”¾è¶…æ—¶ ({elapsed_time:.1f}ç§’)ï¼Œå¼ºåˆ¶åœæ­¢")
                            pygame.mixer.stop()
                            break
                        
                        pygame.time.wait(50)  # å¢åŠ ç­‰å¾…é—´éš”ï¼Œå‡å°‘CPUå ç”¨
                    
                    actual_play_time = time.time() - start_time
                    print(f"âœ… [éŸ³é¢‘çº¿ç¨‹] éŸ³é¢‘æ’­æ”¾å®Œæˆ (å®é™…æ’­æ”¾æ—¶é—´: {actual_play_time:.1f}ç§’)")
                    
                except Exception as e:
                    print(f"âŒ [éŸ³é¢‘çº¿ç¨‹] æ’­æ”¾é”™è¯¯: {str(e)}")
                    # ç¡®ä¿åœæ­¢æ’­æ”¾
                    try:
                        pygame.mixer.stop()
                    except:
                        pass
                
                self.audio_processing = False
                self.audio_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ [éŸ³é¢‘çº¿ç¨‹] å¤„ç†é”™è¯¯: {str(e)}")
                self.audio_processing = False
                time.sleep(0.1)
    
    def generate_embedding(self, text):
        """ç”Ÿæˆæ–‡æœ¬embedding"""
        if not text or not text.strip():
            return None
        
        text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
        
        # æ£€æŸ¥ç¼“å­˜
        with self.cache_lock:
            if text_hash in self.embedding_cache:
                return self.embedding_cache[text_hash]
        
        try:
            response = ollama.embeddings(model=self.embedding_model, prompt=text)
            embedding = np.array(response["embedding"], dtype=np.float32)
            
            # å½’ä¸€åŒ–
            norm = np.linalg.norm(embedding)
            if norm > 0:
                embedding = embedding / norm
            
            # ç¼“å­˜ç»“æœ
            with self.cache_lock:
                self.embedding_cache[text_hash] = embedding
                if len(self.embedding_cache) > 1000:
                    oldest_key = next(iter(self.embedding_cache))
                    del self.embedding_cache[oldest_key]
            
            return embedding
            
        except Exception as e:
            print(f"âŒ Embeddingç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def search_knowledge_base(self, query, top_k=10):
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            query_embedding = self.generate_embedding(query)
            if query_embedding is None:
                return []
            
            query_embedding = query_embedding.reshape(1, -1).astype(np.float32)
            scores, indices = self.faiss_index.search(query_embedding, top_k)
            
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx < len(self.faiss_metadata):
                    metadata = self.faiss_metadata[idx]
                    page_data = self.wiki_pages[idx]
                    
                    results.append({
                        'rank': i + 1,
                        'score': float(score),
                        'title': metadata['title'],
                        'url': metadata['url'],
                        'content': page_data['content'],
                        'content_length': metadata['content_length'],
                        'timestamp': metadata['timestamp']
                    })
            
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            return []
    
    def generate_answer(self, question):
        """ç”Ÿæˆå›ç­”"""
        # æ£€æµ‹ç”¨æˆ·é—®é¢˜è¯­è¨€
        user_language = self.detect_language(question)
        print(f"ğŸ” [LLMçº¿ç¨‹] æ£€æµ‹åˆ°ç”¨æˆ·é—®é¢˜è¯­è¨€: {user_language}")
        
        # æœç´¢çŸ¥è¯†åº“
        search_results = self.search_knowledge_base(question, top_k=5)
        
        if not search_results:
            if user_language == 'zh':
                return "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            else:
                return "Sorry, I couldn't find relevant information in the knowledge base."
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for result in search_results[:3]:  # åªä½¿ç”¨å‰3ä¸ªç»“æœ
            title = result['title']
            content = result['content']
            if content.startswith('[Introduction] '):
                content = content[16:]
            if len(content) > 300:
                content = content[:300] + "..."
            context_parts.append(f"æ–‡æ¡£æ ‡é¢˜: {title}\nå†…å®¹: {content}")
        
        context = "\n\n".join(context_parts)
        
        # æ ¹æ®ç”¨æˆ·è¯­è¨€æ„å»ºä¸åŒçš„prompt
        if user_language == 'zh':
            prompt = f"""è¯·åŸºäºä»¥ä¸‹èµ„æ–™ï¼Œç”¨è¯¦ç»†çš„ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é‡è¦è¦æ±‚ï¼š
1. å¿…é¡»ç”¨ä¸­æ–‡å›ç­”ï¼Œä¸èƒ½ä½¿ç”¨è‹±æ–‡
2. å›ç­”å¿…é¡»æ§åˆ¶åœ¨200-250å­—ä¹‹é—´
3. ä»‹ç»äº§å“æ—¶è¯´"æˆ‘ä»¬çš„xxxäº§å“..."
4. ä¸¥æ ¼åŸºäºæä¾›çš„èµ„æ–™å›ç­”ï¼Œä¸èƒ½ç¼–é€ ä¿¡æ¯
5. è¯­è¨€è¦è¯¦ç»†å®Œæ•´ï¼ŒåŒ…å«äº§å“ç‰¹ç‚¹ã€åŠŸèƒ½å’Œåº”ç”¨åœºæ™¯
6. ä¸è¦é‡å¤èº«ä»½ä»‹ç»
7. ç¡®ä¿å›ç­”æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ®µè½ï¼Œå†…å®¹ä¸°å¯Œè¯¦å®
8. å¯ä»¥é€‚å½“å±•å¼€ç›¸å…³æŠ€æœ¯ç»†èŠ‚å’Œä½¿ç”¨å»ºè®®

ç›¸å…³èµ„æ–™:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·ç”¨200-250å­—çš„è¯¦ç»†ä¸­æ–‡å›ç­”:"""
        else:
            prompt = f"""Please answer the user's question in detailed English based on the following materials.

Important requirements:
1. Must answer in English, not in Chinese
2. Keep the answer within 200-250 words
3. When introducing products, say "our xxx product..."
4. Strictly base your answer on the provided materials, don't fabricate information
5. Be detailed and complete, include product features, functions and use cases
6. Don't repeat identity introductions
7. Ensure the answer is a complete paragraph with rich content
8. You can expand on relevant technical details and usage recommendations

Materials:
{context}

User Question: {question}

Please answer in detailed English within 200-250 words:"""
        
        try:
            # ä½¿ç”¨Ollamaç”Ÿæˆå›ç­”
            system_prompt = 'ç”¨ä¸­æ–‡å›ç­”ï¼ŒåŸºäºèµ„æ–™ï¼Œä¸ç¼–é€ ä¿¡æ¯ï¼Œä¸è¦é‡å¤èº«ä»½ä»‹ç»ã€‚' if user_language == 'zh' else 'Answer in English, based on materials, don\'t fabricate information, don\'t repeat identity introductions.'
            
            response = ollama.chat(
                model='qwen2.5:3b',
                messages=[
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': prompt}
                ],
                options={
                    'temperature': 0.7,
                    'top_p': 0.9,
                    'num_predict': 300,  # å¢åŠ ç”Ÿæˆé•¿åº¦åˆ°300å­—
                }
            )
            
            answer = response['message']['content'].strip()
            
            # åå¤„ç†ï¼šç¡®ä¿å­—æ•°é™åˆ¶
            answer = self.limit_answer_length(answer, min_length=200, max_length=250)
            print(f"ğŸ“Š [LLMçº¿ç¨‹] å›ç­”å­—æ•°: {len(answer)} å­—")
            return answer
            
        except Exception as e:
            print(f"âŒ å›ç­”ç”Ÿæˆå¤±è´¥: {str(e)}")
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›ç­”ã€‚"
    
    def limit_answer_length(self, answer, min_length=200, max_length=250):
        """é™åˆ¶å›ç­”é•¿åº¦"""
        # å¦‚æœå›ç­”å¤ªçŸ­ï¼Œå°è¯•æ‰©å±•
        if len(answer) < min_length:
            # åœ¨å¥å·ã€é—®å·ã€æ„Ÿå¹å·å¤„æ·»åŠ å†…å®¹
            if answer.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ')):
                # å¦‚æœå·²ç»ä»¥æ ‡ç‚¹ç»“å°¾ï¼Œæ·»åŠ æ›´å¤šä¿¡æ¯
                answer = answer + " è¯¥äº§å“å…·æœ‰é«˜æ€§èƒ½ã€æ˜“ç”¨æ€§å¼ºçš„ç‰¹ç‚¹ï¼Œé€‚åˆå„ç§åº”ç”¨åœºæ™¯ã€‚å®ƒé‡‡ç”¨å…ˆè¿›çš„æŠ€æœ¯æ¶æ„ï¼Œæä¾›ç¨³å®šå¯é çš„æ€§èƒ½è¡¨ç°ï¼Œèƒ½å¤Ÿæ»¡è¶³ä¸åŒç”¨æˆ·çš„éœ€æ±‚ã€‚æ— è®ºæ˜¯åˆå­¦è€…è¿˜æ˜¯ä¸“ä¸šå¼€å‘è€…ï¼Œéƒ½èƒ½è½»æ¾ä¸Šæ‰‹ä½¿ç”¨ã€‚"
            else:
                # å¦‚æœæ²¡æœ‰æ ‡ç‚¹ç»“å°¾ï¼Œæ·»åŠ æ ‡ç‚¹å’Œä¿¡æ¯
                answer = answer + "ã€‚è¯¥äº§å“å…·æœ‰é«˜æ€§èƒ½ã€æ˜“ç”¨æ€§å¼ºçš„ç‰¹ç‚¹ï¼Œé€‚åˆå„ç§åº”ç”¨åœºæ™¯ã€‚å®ƒé‡‡ç”¨å…ˆè¿›çš„æŠ€æœ¯æ¶æ„ï¼Œæä¾›ç¨³å®šå¯é çš„æ€§èƒ½è¡¨ç°ï¼Œèƒ½å¤Ÿæ»¡è¶³ä¸åŒç”¨æˆ·çš„éœ€æ±‚ã€‚æ— è®ºæ˜¯åˆå­¦è€…è¿˜æ˜¯ä¸“ä¸šå¼€å‘è€…ï¼Œéƒ½èƒ½è½»æ¾ä¸Šæ‰‹ä½¿ç”¨ã€‚"
        
        # å¦‚æœå›ç­”å¤ªé•¿ï¼Œæˆªæ–­
        if len(answer) > max_length:
            # åœ¨å¥å·ã€é—®å·ã€æ„Ÿå¹å·å¤„æˆªæ–­
            for i in range(max_length, 0, -1):
                if answer[i] in 'ã€‚ï¼ï¼Ÿ':
                    return answer[:i+1]
            
            # å¦‚æœæ²¡æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œç›´æ¥æˆªæ–­
            return answer[:max_length] + "..."
        
        return answer
    
    def detect_language(self, text):
        """æ£€æµ‹æ–‡æœ¬è¯­è¨€"""
        if not text or not text.strip():
            return 'zh'  # é»˜è®¤ä¸ºä¸­æ–‡
        
        # æ£€æµ‹ä¸­æ–‡å­—ç¬¦
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
        english_chars = re.findall(r'[a-zA-Z]', text)
        
        # è®¡ç®—ä¸­è‹±æ–‡æ¯”ä¾‹
        total_chars = len(text.replace(' ', '').replace('\n', ''))
        if total_chars == 0:
            return 'zh'
            
        chinese_ratio = len(chinese_chars) / total_chars
        english_ratio = len(english_chars) / total_chars
        
        # ä¿®å¤é€»è¾‘ï¼šåªè¦åŒ…å«ä¸­æ–‡å­—ç¬¦å°±è®¤ä¸ºæ˜¯ä¸­æ–‡
        if len(chinese_chars) > 0:
            return 'zh'
        elif english_ratio > 0.5:
            return 'en'
        else:
            # å¦‚æœéƒ½ä¸æ˜æ˜¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
            chinese_punctuation = re.findall(r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘]', text)
            if chinese_punctuation:
                return 'zh'
            return 'en'
    
    def ask_question_async(self, question):
        """å¼‚æ­¥æé—®"""
        print(f"\nğŸ¤” ç”¨æˆ·é—®é¢˜: {question}")
        
        # æ£€æµ‹ç”¨æˆ·é—®é¢˜è¯­è¨€
        user_language = self.detect_language(question)
        print(f"ğŸ” æ£€æµ‹åˆ°ç”¨æˆ·é—®é¢˜è¯­è¨€: {user_language}")
        
        def on_answer_generated(answer):
            print(f"\nğŸ’¬ å›ç­”: {answer}")
            
            # æ£€æµ‹AIå›ç­”è¯­è¨€
            answer_language = self.detect_language(answer)
            print(f"ğŸ” æ£€æµ‹åˆ°AIå›ç­”è¯­è¨€: {answer_language}")
            
            # å°†å›ç­”åŠ å…¥TTSé˜Ÿåˆ—
            if self.tts_available:
                self.tts_queue.put({
                    'text': answer,
                    'callback': lambda segments: print(f"ğŸ¤ è¯­éŸ³å·²åŠ å…¥æ’­æ”¾é˜Ÿåˆ—ï¼Œå…±{segments}ä¸ªç‰‡æ®µ")
                })
        
        # å°†é—®é¢˜åŠ å…¥LLMé˜Ÿåˆ—
        self.llm_queue.put({
            'question': question,
            'callback': on_answer_generated
        })
        
        print("ğŸ”„ é—®é¢˜å·²åŠ å…¥å¤„ç†é˜Ÿåˆ—ï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”...")
    
    def show_system_info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        print(f"\nğŸ“Š ç³»ç»Ÿä¿¡æ¯:")
        print(f"   æ€»é¡µé¢æ•°: {len(self.wiki_pages)}")
        print(f"   æ€»å‘é‡æ•°: {self.faiss_index.ntotal}")
        print(f"   å‘é‡ç»´åº¦: {self.metadata['vector_dimension']}")
        print(f"   Embeddingæ¨¡å‹: {self.metadata['embedding_model']}")
        print(f"   TTSç³»ç»Ÿ: {'å¯ç”¨' if self.tts_available else 'ä¸å¯ç”¨'}")
        print(f"   TTSè®¾å¤‡: {self.tts_device}")
        print(f"   ä¸­æ–‡TTS: {'å·²åŠ è½½' if self.tts_pipeline_zh else 'æœªåŠ è½½'}")
        print(f"   è‹±æ–‡TTS: {'å·²åŠ è½½' if self.tts_pipeline_en else 'æœªåŠ è½½'}")
        print(f"   ä¸­æ–‡éŸ³è‰²: {'å·²åŠ è½½' if hasattr(self, 'voice_zf_tensor') and self.voice_zf_tensor is not None else 'æœªåŠ è½½'}")
        print(f"   è‹±æ–‡éŸ³è‰²: {'å·²åŠ è½½' if hasattr(self, 'voice_af_tensor') and self.voice_af_tensor is not None else 'æœªåŠ è½½'}")
        print(f"   ä¸­è‹±æ··åˆ: {'æ”¯æŒ' if hasattr(self, 'voice_zf_tensor') and self.voice_zf_tensor is not None else 'ä¸æ”¯æŒ'}")
        print(f"   éŸ³é¢‘ç³»ç»Ÿ: {'å·²åˆå§‹åŒ–' if self.audio_initialized else 'æœªåˆå§‹åŒ–'}")
        print(f"   å·¥ä½œçº¿ç¨‹: LLM={'è¿è¡Œä¸­' if self.llm_thread and self.llm_thread.is_alive() else 'æœªå¯åŠ¨'}, "
              f"TTS={'è¿è¡Œä¸­' if self.tts_thread and self.tts_thread.is_alive() else 'æœªå¯åŠ¨'}, "
              f"éŸ³é¢‘={'è¿è¡Œä¸­' if self.audio_thread and self.audio_thread.is_alive() else 'æœªå¯åŠ¨'}")
        print(f"   é˜Ÿåˆ—çŠ¶æ€: LLM={self.llm_queue.qsize()}, TTS={self.tts_queue.qsize()}, éŸ³é¢‘={self.audio_queue.qsize()}")
        print(f"   å¤„ç†çŠ¶æ€: LLM={'å¤„ç†ä¸­' if self.llm_processing else 'ç©ºé—²'}, "
              f"TTS={'å¤„ç†ä¸­' if self.tts_processing else 'ç©ºé—²'}, "
              f"éŸ³é¢‘={'å¤„ç†ä¸­' if self.audio_processing else 'ç©ºé—²'}")
    
    def run(self):
        """è¿è¡Œè¯­éŸ³å¯¹è¯åŠ©æ‰‹"""
        print("ğŸ¤– Seeed Studioè¯­éŸ³å¯¹è¯åŠ©æ‰‹")
        print("=" * 50)
        print("æ¬¢è¿ä½¿ç”¨æˆ‘ä»¬çš„æ™ºèƒ½è¯­éŸ³é—®ç­”ç³»ç»Ÿï¼")
        print("æˆ‘æ˜¯Seeed Studioçš„ä¸“å±AIåŠ©æ‰‹ï¼Œæ”¯æŒå®æ—¶è¯­éŸ³å¯¹è¯")
        print("=" * 50)
        
        sample_questions = [
            "ä»‹ç»ä¸€ä¸‹XIAOç³»åˆ—äº§å“",
            "Groveä¼ æ„Ÿå™¨æ¨¡å—æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
            "SenseCAPçš„åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
            "Edge Computingæ˜¯ä»€ä¹ˆï¼Ÿ",
            "reComputeræœ‰ä»€ä¹ˆç‰¹è‰²ï¼Ÿ"
        ]
        
        print(f"\nğŸ’¡ ç¤ºä¾‹é—®é¢˜:")
        for i, question in enumerate(sample_questions, 1):
            print(f"   {i}. {question}")
        
        print(f"\nğŸ’¬ ç°åœ¨å¯ä»¥å¼€å§‹è¯­éŸ³å¯¹è¯äº†ï¼")
        print("ğŸ’¡ è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©ï¼Œ'quit' é€€å‡º")
        print("ğŸ’¡ æ”¯æŒå®æ—¶è¯­éŸ³åˆæˆå’Œæ’­æ”¾")
        print("-" * 50)
        
        try:
            while True:
                try:
                    query = self.safe_input("\nğŸ¤” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ")
                    
                    if not query:
                        continue
                    
                    if query.lower() in ['quit', 'exit', 'q']:
                        print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                        break
                    elif query.lower() == 'help':
                        self.show_help()
                        continue
                    elif query.lower() == 'info':
                        self.show_system_info()
                        continue
                    elif query.lower() == 'sample':
                        print("ğŸ’¡ ç¤ºä¾‹é—®é¢˜:")
                        for i, question in enumerate(sample_questions, 1):
                            print(f"   {i}. {question}")
                        continue
                    
                    if query.isdigit() and 1 <= int(query) <= len(sample_questions):
                        query = sample_questions[int(query) - 1]
                        print(f"ğŸ” é€‰æ‹©çš„é—®é¢˜: {query}")
                    
                    # å¼‚æ­¥å¤„ç†é—®é¢˜
                    self.ask_question_async(query)
                    
                except KeyboardInterrupt:
                    print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
                    break
                except Exception as e:
                    print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
                    continue
                    
        finally:
            # åœæ­¢æ‰€æœ‰çº¿ç¨‹
            self.running = False
            print("ğŸ”„ æ­£åœ¨åœæ­¢å·¥ä½œçº¿ç¨‹...")
            
            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if self.llm_thread and self.llm_thread.is_alive():
                self.llm_thread.join(timeout=2)
            if self.tts_thread and self.tts_thread.is_alive():
                self.tts_thread.join(timeout=2)
            if self.audio_thread and self.audio_thread.is_alive():
                self.audio_thread.join(timeout=2)
            
            print("âœ… è¯­éŸ³å¯¹è¯åŠ©æ‰‹å·²åœæ­¢")
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("   - ç›´æ¥è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿä¼šå®æ—¶ç”Ÿæˆè¯­éŸ³å›ç­”")
        print("   - è¾“å…¥ 'help' æ˜¾ç¤ºå¸®åŠ©")
        print("   - è¾“å…¥ 'info' æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯")
        print("   - è¾“å…¥ 'sample' æ˜¾ç¤ºç¤ºä¾‹é—®é¢˜")
        print("   - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç¨‹åº")
        print("\nğŸš€ ç³»ç»Ÿç‰¹æ€§:")
        print("   - å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼Œå“åº”æ›´å¿«")
        print("   - å®æ—¶è¯­éŸ³åˆæˆå’Œæ’­æ”¾")
        print("   - åŒè¯­è¨€TTSæ”¯æŒï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰")
        print("   - æ™ºèƒ½è¯­è¨€æ£€æµ‹ï¼Œè‡ªåŠ¨é€‰æ‹©TTSæ¨¡å‹")
        print("   - åŸºäºKokoro TTSçš„é«˜è´¨é‡è¯­éŸ³")
        print("   - æ”¯æŒGPUåŠ é€Ÿæ¨ç†")
        print("   - æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œé‡å¤é—®é¢˜ç§’ç­”")
        print("   - æµå¼å›ç­”æ˜¾ç¤ºï¼Œæ‰“å­—æœºæ•ˆæœ")


def main():
    """ä¸»å‡½æ•°"""
    try:
        assistant = VoiceChatAssistant()
        assistant.run()
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’Œä¾èµ–é¡¹")


if __name__ == "__main__":
    main()