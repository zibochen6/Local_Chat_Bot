#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºæœ¬åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import json
import os
import pickle
import numpy as np
import faiss
import ollama
import time
import re
import sys
import readline
import hashlib
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor
import threading

class BasicQASystem:
    def __init__(self):
        self.faiss_index = None
        self.faiss_metadata = None
        self.wiki_pages = []
        self.embedding_model = "nomic-embed-text"
        
        # æ€§èƒ½ä¼˜åŒ–ç›¸å…³
        self.embedding_cache = {}
        self.cache_lock = threading.Lock()
        
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–åŸºæœ¬é—®ç­”ç³»ç»Ÿ...")
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        self.check_data_files()
        
        # æ£€æŸ¥ Ollama æœåŠ¡
        self.check_ollama_service()
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        self.initialize_system()
    
    def check_data_files(self):
        """æ£€æŸ¥å¿…è¦çš„æ•°æ®æ–‡ä»¶"""
        required_files = [
            "./data_base/faiss_index.bin",
            "./data_base/faiss_metadata.pkl",
            "./data_base/seeed_wiki_embeddings_db.json"
        ]
        
        missing_files = []
        for file in required_files:
            if not os.path.exists(file):
                missing_files.append(file)
        
        if missing_files:
            print("âŒ ç¼ºå°‘å¿…è¦çš„æ•°æ®æ–‡ä»¶:")
            for file in missing_files:
                print(f"   - {file}")
            print("\nğŸ’¡ è¯·å…ˆè¿è¡Œçˆ¬è™«è„šæœ¬è·å–æ•°æ®:")
            print("   python scrape_with_embeddings.py")
            raise FileNotFoundError(f"ç¼ºå°‘æ•°æ®æ–‡ä»¶: {', '.join(missing_files)}")
        
        print("âœ… æ‰€æœ‰å¿…è¦çš„æ•°æ®æ–‡ä»¶å·²æ‰¾åˆ°")
    
    def check_ollama_service(self):
        """æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€"""
        try:
            models = ollama.list()
            print(f"âœ… Ollama æœåŠ¡æ­£å¸¸ï¼Œå¯ç”¨æ¨¡å‹: {len(models['models'])} ä¸ª")
            
            model_names = [model['name'] for model in models['models']]
            if 'nomic-embed-text:latest' not in model_names:
                print("âš ï¸  æœªæ‰¾åˆ° nomic-embed-text æ¨¡å‹ï¼Œæ­£åœ¨å®‰è£…...")
                ollama.pull('nomic-embed-text')
                print("âœ… nomic-embed-text æ¨¡å‹å®‰è£…å®Œæˆ")
            else:
                print("âœ… nomic-embed-text æ¨¡å‹å·²å®‰è£…")
                
        except Exception as e:
            print(f"âŒ Ollama æœåŠ¡æ£€æŸ¥å¤±è´¥: {str(e)}")
            raise
    
    def initialize_system(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...")
        
        try:
            # åŠ è½½ FAISS ç´¢å¼•
            print("ğŸ” åŠ è½½ FAISS ç´¢å¼•...")
            self.faiss_index = faiss.read_index("./data_base/faiss_index.bin")
            print(f"âœ… FAISS ç´¢å¼•åŠ è½½å®Œæˆ: {self.faiss_index.ntotal} ä¸ªå‘é‡")
            
            # åŠ è½½å‘é‡å…ƒæ•°æ®
            print("ğŸ“Š åŠ è½½å‘é‡å…ƒæ•°æ®...")
            with open("./data_base/faiss_metadata.pkl", 'rb') as f:
                self.faiss_metadata = pickle.load(f)
            print(f"âœ… å…ƒæ•°æ®åŠ è½½å®Œæˆ: {len(self.faiss_metadata)} æ¡è®°å½•")
            
            # åŠ è½½ Wiki é¡µé¢æ•°æ®
            print("ğŸ“š åŠ è½½ Wiki é¡µé¢æ•°æ®...")
            with open("./data_base/seeed_wiki_embeddings_db.json", 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.wiki_pages = data['pages']
                self.metadata = data['metadata']
            print(f"âœ… é¡µé¢æ•°æ®åŠ è½½å®Œæˆ: {len(self.wiki_pages)} ä¸ªé¡µé¢")
            
            # æµ‹è¯• Embedding æ¨¡å‹
            print("ğŸ¤– æµ‹è¯• Embedding æ¨¡å‹...")
            test_embedding = self.generate_embedding("test")
            if test_embedding is None:
                raise Exception("Embedding ç”Ÿæˆå¤±è´¥")
            print(f"âœ… Embedding æ¨¡å‹æµ‹è¯•æˆåŠŸ: {len(test_embedding)} ç»´")
            
            print("ğŸ‰ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            raise
    
    def generate_embedding(self, text):
        """ä½¿ç”¨ Ollama ç”Ÿæˆæ–‡æœ¬çš„ embedding å‘é‡"""
        if not text or not text.strip():
            return None
            
        try:
            response = ollama.embeddings(model=self.embedding_model, prompt=text)
            embedding = response["embedding"]
            embedding = np.array(embedding, dtype=np.float32)
            
            # å½’ä¸€åŒ–
            norm = np.linalg.norm(embedding)
            if norm == 0:
                return None
            embedding = embedding / norm
            
            return embedding
            
        except Exception as e:
            print(f"âŒ Embedding ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def search_knowledge_base(self, query, top_k=10):
        """åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³å†…å®¹"""
        try:
            query_embedding = self.generate_embedding(query)
            if query_embedding is None:
                return []
            
            query_embedding = query_embedding.reshape(1, -1).astype(np.float32)
            scores, indices = self.faiss_index.search(query_embedding, top_k)
            
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx < len(self.faiss_metadata):
                    metadata = self.faiss_metadata[idx]
                    page_data = self.wiki_pages[idx]
                    
                    results.append({
                        'rank': i + 1,
                        'score': float(score),
                        'title': metadata['title'],
                        'url': metadata['url'],
                        'content': page_data['content'],
                        'content_length': metadata['content_length'],
                        'timestamp': metadata['timestamp']
                    })
            
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            return []
    
    def ask_question(self, question):
        """æé—®å¹¶è·å–å›ç­”"""
        print(f"\nğŸ¤” ç”¨æˆ·é—®é¢˜: {question}")
        
        # æœç´¢çŸ¥è¯†åº“
        print("ğŸ” æ­£åœ¨æœç´¢çŸ¥è¯†åº“...")
        start_time = time.time()
        search_results = self.search_knowledge_base(question, top_k=5)
        search_time = time.time() - start_time
        
        if not search_results:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
            return
        
        print(f"âœ… æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.3f} ç§’")
        print(f"ğŸ“Š æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        # æ˜¾ç¤ºæœç´¢ç»“æœ
        print(f"ğŸ” æœç´¢ç»“æœ:")
        for i, result in enumerate(search_results[:3]):
            print(f"  {i+1}. {result['title']}")
            print(f"     ç›¸å…³åº¦: {result['score']:.3f}")
            print(f"     URL: {result['url']}")
            print()
        
        # ç®€å•å›ç­”
        top_result = search_results[0]
        content = top_result['content']
        if content.startswith('[Introduction] '):
            content = content[16:]
        
        answer = f"æ ¹æ®æœç´¢ç»“æœï¼Œ{top_result['title']} æä¾›äº†ç›¸å…³ä¿¡æ¯ï¼š{content[:200]}..."
        print(f"\nğŸ’¬ å›ç­”:")
        print(f"{answer}")
    
    def run(self):
        """è¿è¡Œé—®ç­”ç³»ç»Ÿ"""
        print("ğŸ¤– Seeed Studioï¼ˆçŸ½é€’ç§‘æŠ€ï¼‰åŸºæœ¬æ™ºèƒ½åŠ©æ‰‹")
        print("=" * 50)
        print("æ¬¢è¿ä½¿ç”¨åŸºæœ¬é—®ç­”ç³»ç»Ÿï¼")
        print("=" * 50)
        
        sample_questions = [
            "ä»‹ç»ä¸€ä¸‹XIAOç³»åˆ—äº§å“",
            "Groveä¼ æ„Ÿå™¨æ¨¡å—æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
            "SenseCAPçš„åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        print(f"\nğŸ’¡ ç¤ºä¾‹é—®é¢˜:")
        for i, question in enumerate(sample_questions, 1):
            print(f"   {i}. {question}")
        
        print(f"\nğŸ’¬ ç°åœ¨å¯ä»¥å¼€å§‹æé—®äº†ï¼")
        print("ğŸ’¡ è¾“å…¥ 'quit' é€€å‡º")
        print("-" * 50)
        
        try:
            while True:
                try:
                    query = input("\nğŸ¤” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                    
                    if not query:
                        continue
                    
                    if query.lower() in ['quit', 'exit', 'q']:
                        print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                        break
                    
                    if query.isdigit() and 1 <= int(query) <= len(sample_questions):
                        query = sample_questions[int(query) - 1]
                        print(f"ğŸ” é€‰æ‹©çš„é—®é¢˜: {query}")
                    
                    self.ask_question(query)
                    
                except KeyboardInterrupt:
                    print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
                    break
                except Exception as e:
                    print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
                    continue
                    
        finally:
            print("ğŸ‘‹ ç¨‹åºç»“æŸ")

def main():
    """ä¸»å‡½æ•°"""
    try:
        qa_system = BasicQASystem()
        qa_system.run()
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’Œ Ollama æœåŠ¡")

if __name__ == "__main__":
    main()


