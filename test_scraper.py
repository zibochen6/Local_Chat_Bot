#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• Seeed Wiki çˆ¬è™«åŠŸèƒ½
"""

import os
import json
from scrape_with_embeddings import OptimizedWikiScraper

def test_scraper():
    """æµ‹è¯•çˆ¬è™«åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯• Seeed Wiki çˆ¬è™«...")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    scraper = OptimizedWikiScraper()
    
    # æµ‹è¯•æ•°æ®ç›®å½•åˆ›å»º
    print(f"ğŸ“ æ•°æ®ç›®å½•: {scraper.data_dir}")
    print(f"ğŸ“„ æ•°æ®åº“æ–‡ä»¶: {scraper.db_file}")
    print(f"ğŸ” FAISSç´¢å¼•æ–‡ä»¶: {scraper.faiss_index_file}")
    
    # æ£€æŸ¥ç°æœ‰æ•°æ®
    if os.path.exists(scraper.db_file):
        with open(scraper.db_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            pages = data.get('pages', [])
            metadata = data.get('metadata', {})
            print(f"ğŸ“Š ç°æœ‰æ•°æ®ç»Ÿè®¡:")
            print(f"   - æ€»é¡µé¢æ•°: {len(pages)}")
            print(f"   - å‘é‡ç»´åº¦: {metadata.get('vector_dimension', 'N/A')}")
            print(f"   - æœ€åæ›´æ–°: {metadata.get('last_update', 'N/A')}")
            print(f"   - æ”¯æŒè¯­è¨€: {metadata.get('languages', [])}")
            
            # è¯­è¨€ç»Ÿè®¡
            chinese_pages = len([p for p in pages if p.get('language') == 'ä¸­æ–‡'])
            english_pages = len([p for p in pages if p.get('language') == 'English'])
            print(f"   - ä¸­æ–‡é¡µé¢: {chinese_pages}")
            print(f"   - è‹±æ–‡é¡µé¢: {english_pages}")
    else:
        print("ğŸ“‚ æ²¡æœ‰ç°æœ‰æ•°æ®ï¼Œå°†è¿›è¡Œé¦–æ¬¡çˆ¬å–")
    
    # æµ‹è¯•URLéªŒè¯
    test_urls = [
        "https://wiki.seeedstudio.com/Getting_Started/",
        "https://wiki.seeedstudio.com/zh/Getting_Started/",
        "https://wiki.seeedstudio.com/XIAO/",
        "https://wiki.seeedstudio.com/zh/XIAO/",
        "https://wiki.seeedstudio.com/test.pdf",  # åº”è¯¥è¢«æ’é™¤
        "https://wiki.seeedstudio.com/api/test",  # åº”è¯¥è¢«æ’é™¤
    ]
    
    print("\nğŸ”— æµ‹è¯•URLéªŒè¯:")
    for url in test_urls:
        is_valid = scraper.is_valid_wiki_url(url)
        print(f"   {url}: {'âœ…' if is_valid else 'âŒ'}")
    
    # æµ‹è¯•embeddingç”Ÿæˆ
    print("\nğŸ§  æµ‹è¯•Embeddingç”Ÿæˆ:")
    test_texts = [
        "Hello, this is a test in English.",
        "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æµ‹è¯•ã€‚",
        "This is a mixed text with ä¸­æ–‡ and English content."
    ]
    
    for text in test_texts:
        embedding = scraper.generate_embedding(text)
        if embedding is not None:
            print(f"   âœ… '{text[:30]}...': {embedding.shape}")
        else:
            print(f"   âŒ '{text[:30]}...': ç”Ÿæˆå¤±è´¥")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("   python scrape_with_embeddings.py --mode incremental  # å¢é‡æ›´æ–°")
    print("   python scrape_with_embeddings.py --mode full         # å®Œæ•´çˆ¬å–")
    print("   python scrape_with_embeddings.py --mode schedule     # å®šæ—¶æ›´æ–°")
    print("   python scrape_with_embeddings.py --mode monitor      # æŒç»­ç›‘æ§æ¨¡å¼")
    print("\nğŸ“Š ç›‘æ§æ¨¡å¼åŠŸèƒ½:")
    print("   - å®æ—¶æ£€æŸ¥æ–°é¡µé¢å¹¶æ›´æ–°åˆ°æœ¬åœ°")
    print("   - æ¯å¤©å‡Œæ™¨12ç‚¹è‡ªåŠ¨è¿›è¡Œå®Œæ•´æ•°æ®åº“æ›´æ–°")
    print("   - æ¯30åˆ†é’Ÿå¿«é€Ÿæ£€æŸ¥ä¸€æ¬¡æ–°é¡µé¢")

if __name__ == "__main__":
    test_scraper()
