
from kokoro import KPipeline, KModel
import pygame
import numpy as np
import torch
import time
import soundfile as sf
import os

# æ£€æŸ¥GPUå¯ç”¨æ€§
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
    print(f"å½“å‰CUDAè®¾å¤‡: {torch.cuda.current_device()}")
    print(f"è®¾å¤‡åç§°: {torch.cuda.get_device_name()}")

# åˆå§‹åŒ–pygameéŸ³é¢‘ç³»ç»Ÿ
pygame.mixer.init(frequency=24000, size=-16, channels=1, buffer=1024)
print("âœ“ pygameéŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

# è®¾ç½®æ¨¡å‹è·¯å¾„
repo_id = 'hexgrad/Kokoro-82M-v1.1-zh'
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
model_path = 'ckpts/kokoro-v1.1/kokoro-v1_1-zh.pth'
config_path = 'ckpts/kokoro-v1.1/config.json'

if not os.path.exists(model_path):
    print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    print("è¯·å…ˆä¸‹è½½æ¨¡å‹æ–‡ä»¶:")
    print("export HF_ENDPOINT=https://hf-mirror.com")
    print("huggingface-cli download --resume-download hexgrad/Kokoro-82M-v1.1-zh --local-dir ./ckpts/kokoro-v1.1")
    exit(1)

# åŠ è½½éŸ³è‰²æ–‡ä»¶
voice_zf = "zf_001"
voice_af = 'af_heart'
voice_zf_path = f'ckpts/kokoro-v1.1/voices/{voice_zf}.pt'
voice_af_path = f'ckpts/kokoro-v1.1/voices/{voice_af}.pt'

if os.path.exists(voice_zf_path):
    voice_zf_tensor = torch.load(voice_zf_path, weights_only=True)
    print(f"âœ“ åŠ è½½éŸ³è‰²: {voice_zf}")
else:
    print(f"âŒ éŸ³è‰²æ–‡ä»¶ä¸å­˜åœ¨: {voice_zf_path}")
    voice_zf_tensor = None

if os.path.exists(voice_af_path):
    voice_af_tensor = torch.load(voice_af_path, weights_only=True)
    print(f"âœ“ åŠ è½½éŸ³è‰²: {voice_af}")
else:
    print(f"âŒ éŸ³è‰²æ–‡ä»¶ä¸å­˜åœ¨: {voice_af_path}")
    voice_af_tensor = None

# åŠ è½½æ¨¡å‹
print("æ­£åœ¨åŠ è½½Kokoroæ¨¡å‹...")
model = KModel(model=model_path, config=config_path, repo_id=repo_id).to(device).eval()
print("âœ“ Kokoroæ¨¡å‹åŠ è½½å®Œæˆ")

# åˆå§‹åŒ–è‹±æ–‡ç®¡é“
print("åˆå§‹åŒ–è‹±æ–‡ç®¡é“...")
en_pipeline = KPipeline(lang_code='a', repo_id=repo_id, model=model)

# å®šä¹‰è‹±æ–‡å›è°ƒå‡½æ•°ï¼Œç”¨äºå¤„ç†ä¸­è‹±æ··æ‚æ–‡æœ¬ä¸­çš„è‹±æ–‡éƒ¨åˆ†
def en_callable(text):
    """
    è‹±æ–‡å›è°ƒå‡½æ•°ï¼Œå¤„ç†ä¸­è‹±æ··æ‚æ–‡æœ¬ä¸­çš„è‹±æ–‡éƒ¨åˆ†
    è¿”å›è‹±æ–‡æ–‡æœ¬çš„éŸ³ç´ è¡¨ç¤º
    """
    print(f"    å¤„ç†è‹±æ–‡æ–‡æœ¬: '{text}'")
    
    # ç‰¹æ®Šè¯æ±‡çš„éŸ³ç´ æ˜ å°„
    if text == 'Kokoro':
        return 'kËˆOkÉ™É¹O'
    elif text == 'Sol':
        return 'sËˆOl'
    elif text == 'reComputer':
        return 'riËkÉ™mËˆpjuËtÉ™r'
    elif text == 'Jetson':
        return 'ËˆdÊ’É›tsÉ™n'
    elif text == 'Hello':
        return 'hÉ™ËˆloÊŠ'
    elif text == 'world':
        return 'wÉœËrld'
    elif text == 'Welcome':
        return 'ËˆwelkÉ™m'
    elif text == 'to':
        return 'tuË'
    elif text == 'TTS':
        return 'tiËtiËËˆes'
    elif text == 'AI':
        return 'eÉªËˆaÉª'
    elif text == 'technology':
        return 'tekËˆnÉ‘ËlÉ™dÊ’i'
    elif text == 'is':
        return 'Éªz'
    elif text == 'advancing':
        return 'É™dËˆvÃ¦nsÉªÅ‹'
    elif text == 'rapidly':
        return 'ËˆrÃ¦pÉªdli'
    elif text == 'It\'s':
        return 'Éªts'
    elif text == 'a':
        return 'É™'
    elif text == 'beautiful':
        return 'ËˆbjuËtÉªfÉ™l'
    elif text == 'day':
        return 'deÉª'
    elif text == 'today':
        return 'tÉ™ËˆdeÉª'
    
    # å¯¹äºå…¶ä»–è‹±æ–‡è¯æ±‡ï¼Œä½¿ç”¨è‹±æ–‡ç®¡é“ç”ŸæˆéŸ³ç´ 
    try:
        result = next(en_pipeline(text, voice=voice_af_tensor if voice_af_tensor is not None else voice_zf_tensor))
        return result.phonemes
    except Exception as e:
        print(f"    è­¦å‘Š: æ— æ³•å¤„ç†è‹±æ–‡æ–‡æœ¬ '{text}': {e}")
        # è¿”å›åŸå§‹æ–‡æœ¬ä½œä¸ºfallback
        return text

# åˆå§‹åŒ–ä¸­æ–‡ç®¡é“ï¼Œä½¿ç”¨en_callableå¤„ç†è‹±æ–‡éƒ¨åˆ†
print("åˆå§‹åŒ–ä¸­æ–‡ç®¡é“ï¼ˆæ”¯æŒä¸­è‹±æ··åˆï¼‰...")
pipeline = KPipeline(lang_code='z', repo_id=repo_id, model=model, en_callable=en_callable)




print("âœ“ Kokoro TTSç®¡é“åˆå§‹åŒ–å®Œæˆ")

# ä¸­è‹±æ–‡æ··åˆæµ‹è¯•æ–‡æœ¬
texts = [
    "è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡è¯­éŸ³åˆæˆæµ‹è¯•ï¼Œæµ‹è¯•è‹±æ–‡è¾“å‡ºï¼šreComputerã€Jetsonã€‚",
    "Hello world! ä½ å¥½ä¸–ç•Œï¼è¿™æ˜¯ä¸€ä¸ªä¸­è‹±æ–‡æ··åˆçš„è¯­éŸ³åˆæˆæµ‹è¯•ã€‚",
    "æ¬¢è¿ä½¿ç”¨Kokoro TTSå¼•æ“ï¼Œå®ƒæ”¯æŒä¸­è‹±æ–‡æ··åˆè¯­éŸ³åˆæˆã€‚Welcome to Kokoro TTS!",
    "äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•è¿…é€Ÿï¼ŒAI technology is advancing rapidlyã€‚",
    "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼ŒIt's a beautiful day todayã€‚",
    "Kokoroæ˜¯ä¸€ä¸ªä¼˜ç§€çš„TTSå¼•æ“ï¼ŒSolæ˜¯å¦ä¸€ä¸ªé€‰æ‹©ã€‚",
    "Helloï¼Œæ¬¢è¿ä½¿ç”¨æˆ‘ä»¬çš„AIè¯­éŸ³åˆæˆç³»ç»Ÿï¼"
]

# é€‰æ‹©è¦ä½¿ç”¨çš„éŸ³è‰²
selected_voice = voice_zf_tensor if voice_zf_tensor is not None else voice_af_tensor
voice_name = voice_zf if voice_zf_tensor is not None else voice_af

if selected_voice is None:
    print("âŒ æ²¡æœ‰å¯ç”¨çš„éŸ³è‰²æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤éŸ³è‰²")
    selected_voice = 'af_heart'
    voice_name = 'af_heart'

print(f"ä½¿ç”¨éŸ³è‰²: {voice_name}")
print(f"è‹±æ–‡å›è°ƒå‡½æ•°å·²é…ç½®ï¼Œæ”¯æŒä¸­è‹±æ··åˆæ–‡æœ¬å¤„ç†")

# æµ‹è¯•æ¯ä¸ªæ–‡æœ¬
for i, text in enumerate(texts):
    print(f"\n{'='*50}")
    print(f"æµ‹è¯•æ–‡æœ¬ {i+1}: {text}")
    print(f"{'='*50}")
    
    print("æ­£åœ¨ç”Ÿæˆè¯­éŸ³ï¼ˆä¸­è‹±æ··åˆå¤„ç†ï¼‰...")
    start_time = time.time()
    generator = pipeline(text, voice=selected_voice)

    # å¤„ç†éŸ³é¢‘ç”Ÿæˆ
    for j, (gs, ps, audio) in enumerate(generator):
        segment_start_time = time.time()
        print(f"  ç‰‡æ®µ {j}: ç”ŸæˆçŠ¶æ€={gs}, å¤„ç†çŠ¶æ€={ps}")
        
        # è½¬æ¢éŸ³é¢‘æ ¼å¼ä¸ºpygameå¯æ’­æ”¾çš„æ ¼å¼
        if isinstance(audio, (np.ndarray, torch.Tensor)):
            # å¦‚æœæ˜¯torch.Tensorï¼Œè½¬æ¢ä¸ºnumpyæ•°ç»„
            if isinstance(audio, torch.Tensor):
                audio = audio.detach().cpu().numpy()
                print(f"    ä»torch.Tensorè½¬æ¢ä¸ºnumpyæ•°ç»„")
            
            print(f"    éŸ³é¢‘å½¢çŠ¶: {audio.shape}, æ•°æ®ç±»å‹: {audio.dtype}")
            print(f"    éŸ³é¢‘èŒƒå›´: [{np.min(audio):.4f}, {np.max(audio):.4f}]")
            
            # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯float32æ ¼å¼ï¼ŒèŒƒå›´åœ¨[-1, 1]
            if audio.dtype != np.float32:
                audio = audio.astype(np.float32)
            
            # å½’ä¸€åŒ–éŸ³é¢‘
            max_val = np.max(np.abs(audio))
            if max_val > 1.0:
                audio = audio / max_val
                print(f"    éŸ³é¢‘å·²å½’ä¸€åŒ–ï¼Œæœ€å¤§å€¼ä¸º: {max_val:.4f}")
            
            # è½¬æ¢ä¸ºint16æ ¼å¼
            audio_int16 = (audio * 32767).astype(np.int16)
            print(f"    è½¬æ¢åéŸ³é¢‘èŒƒå›´: [{np.min(audio_int16)}, {np.max(audio_int16)}]")
            
            # åˆ›å»ºpygame Soundå¯¹è±¡å¹¶æ’­æ”¾
            try:
                sound = pygame.sndarray.make_sound(audio_int16)
                sound.play()
                print(f"    å¼€å§‹æ’­æ”¾ç‰‡æ®µ {j}...")
                
                # ç­‰å¾…å½“å‰ç‰‡æ®µæ’­æ”¾å®Œæˆ
                while pygame.mixer.get_busy():
                    pygame.time.wait(10)
                
                segment_end_time = time.time()
                segment_duration = segment_end_time - segment_start_time
                print(f"    âœ“ ç‰‡æ®µ {j} æ’­æ”¾å®Œæˆ (ç”¨æ—¶: {segment_duration:.2f}ç§’)")
            except Exception as e:
                print(f"    âŒ æ’­æ”¾ç‰‡æ®µ {j} æ—¶å‡ºé”™: {e}")
        else:
            print(f"    âŒ ç‰‡æ®µ {j} éŸ³é¢‘æ•°æ®æ ¼å¼é”™è¯¯: {type(audio)}")
    
    text_time = time.time() - start_time
    print(f"âœ“ æ–‡æœ¬ {i+1} å¤„ç†å®Œæˆ (æ€»ç”¨æ—¶: {text_time:.2f}ç§’)")
    
    # åœ¨æ–‡æœ¬ä¹‹é—´æ·»åŠ çŸ­æš‚åœé¡¿
    if i < len(texts) - 1:
        print("â¸ï¸  æ–‡æœ¬é—´åœé¡¿...")
        pygame.time.wait(1000)  # 1ç§’åœé¡¿

print(f"\nğŸ‰ æ‰€æœ‰ä¸­è‹±æ–‡æ··åˆè¯­éŸ³æ’­æ”¾å®Œæˆï¼")
print(f"ğŸ“Š å…±å¤„ç†äº† {len(texts)} ä¸ªæµ‹è¯•æ–‡æœ¬")
