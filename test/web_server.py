#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WebæœåŠ¡å™¨ - æä¾›æ‰‹æœºç«¯è®¿é—®é¡µé¢
"""

import json
import logging
import time
from typing import Dict, Any

from flask import Flask, render_template, request, jsonify, session, redirect
from config import FLASK_HOST, FLASK_PORT, PRODUCTS_DB, JETSON_IP
import ollama
import json
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.secret_key = 'recomputer_secret_key'  # ç”¨äºsession

# å­˜å‚¨äº§å“è¯·æ±‚çŠ¶æ€
request_status = {}

@app.route('/')
def index():
    """ä¸»é¡µ"""
    # è·å–ç”¨æˆ·è¯­è¨€åå¥½ï¼Œé»˜è®¤ä¸ºä¸­æ–‡
    language = session.get('language', 'zh')
    return render_template('index.html', products=PRODUCTS_DB, language=language, jetson_ip=JETSON_IP)

@app.route('/switch_language/<language>')
def switch_language(language):
    """åˆ‡æ¢è¯­è¨€"""
    if language in ['zh', 'en']:
        session['language'] = language
        print(f"è¯­è¨€å·²åˆ‡æ¢åˆ°: {language}")
    return redirect(request.referrer or '/')

@app.route('/api/ai_explanation', methods=['POST'])
def get_ai_explanation():
    """è·å–AIè®²è§£ï¼ˆè°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹ï¼‰"""
    try:
        data = request.get_json()
        product_id = data.get('product_id')
        language = data.get('language', 'zh')
        
        if not product_id:
            return jsonify({'error': 'ç¼ºå°‘äº§å“ID'}), 400
            
        product = PRODUCTS_DB.get(product_id)
        if not product:
            return jsonify({'error': 'äº§å“ä¸å­˜åœ¨'}), 404
            
        # è°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹ç”Ÿæˆè®²è§£
        ai_explanation = generate_ai_explanation_with_llm(product, language)
        
        response = {
            'product_id': product_id,
            'ai_explanation': ai_explanation,
            'language': language,
            'timestamp': int(time.time())
        }
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"è·å–AIè®²è§£æ—¶å‡ºé”™: {e}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

def generate_ai_explanation_with_llm(product, language='zh'):
    """ä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹ç”Ÿæˆäº§å“è®²è§£"""
    try:
        # æ„å»ºäº§å“ä¿¡æ¯ä¸Šä¸‹æ–‡
        if language == 'zh':
            context = f"""
äº§å“åç§°: {product['name']}
äº§å“æè¿°: {product['description']}
ä¸»è¦ç‰¹æ€§: {', '.join(product['features'])}
æŠ€æœ¯è§„æ ¼:
- AIæ€§èƒ½: {product['specs']['ai_performance']}
- GPU: {product['specs']['gpu']}
- CPU: {product['specs']['cpu']}
- å†…å­˜: {product['specs']['memory']}
- å­˜å‚¨: {product['specs']['storage']}
- è§†é¢‘ç¼–ç : {product['specs']['video_encoder']}
- è§†é¢‘è§£ç : {product['specs']['video_decoder']}
- æ¥å£: {product['specs']['interfaces']}

è¯·è¯¦ç»†ä»‹ç»è¿™æ¬¾äº§å“çš„ç‰¹ç‚¹ã€åº”ç”¨åœºæ™¯å’ŒæŠ€æœ¯ä¼˜åŠ¿ï¼Œç”¨ä¸­æ–‡å›ç­”ã€‚
"""
            system_prompt = "ä½ æ˜¯Seeed Studioçš„æŠ€æœ¯ä¸“å®¶ï¼Œè¯·ç”¨ä¸“ä¸šä¸”æ˜“æ‡‚çš„ä¸­æ–‡ä»‹ç»äº§å“ã€‚"
        else:
            context = f"""
Product Name: {product['name_en']}
Product Description: {product['description_en']}
Key Features: {', '.join(product['features_en'])}
Technical Specifications:
- AI Performance: {product['specs']['ai_performance']}
- GPU: {product['specs']['gpu']}
- CPU: {product['specs']['cpu']}
- Memory: {product['specs']['memory']}
- Storage: {product['specs']['storage']}
- Video Encoder: {product['specs']['video_encoder']}
- Video Decoder: {product['specs']['video_decoder']}
- Interfaces: {product['specs']['interfaces']}

Please provide a detailed introduction to this product's features, applications, and technical advantages in English.
"""
            system_prompt = "You are a technical expert at Seeed Studio. Please introduce the product professionally and understandably in English."
        
        # è°ƒç”¨Ollamaæœ¬åœ°å¤§æ¨¡å‹
        response = ollama.chat(
            model='qwen2.5:3b',  # ä½¿ç”¨qwen2.5:3bæ¨¡å‹
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': context}
            ],
            options={
                'temperature': 0.7,
                'top_p': 0.9,
                'num_predict': 500,
            }
        )
        
        return response['message']['content'].strip()
        
    except Exception as e:
        logger.error(f"AIè®²è§£ç”Ÿæˆå¤±è´¥: {e}")
        # è¿”å›å¤‡ç”¨è®²è§£
        if language == 'zh':
            return f"""
{product['name']}æ˜¯çŸ½é€’ç§‘æŠ€åŸºäºNVIDIA Jetson Orin NXå¹³å°å¼€å‘çš„é«˜æ€§èƒ½è¾¹ç¼˜AIè®¡ç®—è®¾å¤‡ã€‚

è¿™æ¬¾äº§å“å…·æœ‰ä»¥ä¸‹æ ¸å¿ƒä¼˜åŠ¿ï¼š

ğŸ¯ **å¼ºå¤§çš„AIæ€§èƒ½**: æä¾›70-100 TOPSçš„AIè®¡ç®—èƒ½åŠ›ï¼Œèƒ½å¤Ÿè¿è¡Œå¤æ‚çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œç®—æ³•ã€‚

ğŸš€ **å…ˆè¿›çš„ç¡¬ä»¶æ¶æ„**: é‡‡ç”¨1024æ ¸NVIDIA Ampereæ¶æ„GPUï¼Œé…å¤‡32ä¸ªTensor Coreï¼Œæ”¯æŒæœ€æ–°çš„AIæ¡†æ¶å¦‚TensorFlowã€PyTorchç­‰ã€‚

ğŸ’¾ **é«˜é€Ÿå†…å­˜ç³»ç»Ÿ**: 8-16GB LPDDR5å†…å­˜ï¼Œå¸¦å®½é«˜è¾¾102.4GB/sï¼Œç¡®ä¿AIä»»åŠ¡çš„é«˜æ•ˆæ‰§è¡Œã€‚

ğŸ“¹ **ä¸“ä¸šè§†é¢‘å¤„ç†**: æ”¯æŒ4Kè§†é¢‘ç¼–è§£ç ï¼Œ12è·¯1080p30ç¼–ç å’Œ4è·¯4K30è§£ç èƒ½åŠ›ï¼Œé€‚åˆè§†é¢‘åˆ†æåº”ç”¨ã€‚

ğŸ”Œ **ä¸°å¯Œçš„æ¥å£é…ç½®**: æä¾›4ä¸ªUSB 3.2æ¥å£ã€HDMI 2.1ã€2ä¸ªCSIæ‘„åƒå¤´æ¥å£ã€åƒå…†ä»¥å¤ªç½‘ã€M.2æ‰©å±•æ§½ç­‰ï¼Œæ»¡è¶³å„ç§åº”ç”¨éœ€æ±‚ã€‚

reComputer J40xç‰¹åˆ«é€‚ç”¨äºæœºå™¨äººã€æ— äººæœºã€æ™ºèƒ½ç›‘æ§ã€å·¥ä¸šè‡ªåŠ¨åŒ–ã€è¾¹ç¼˜AIæ¨ç†ç­‰éœ€è¦æœ¬åœ°AIå¤„ç†èƒ½åŠ›çš„åœºæ™¯ï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šçº§çš„è¾¹ç¼˜è®¡ç®—è§£å†³æ–¹æ¡ˆã€‚
"""
        else:
            return f"""
{product['name_en']} is a high-performance edge AI computing device developed by Seeed Studio based on the NVIDIA Jetson Orin NX platform.

This product offers the following core advantages:

ğŸ¯ **Powerful AI Performance**: Provides 70-100 TOPS of AI computing power, capable of running complex deep learning models and algorithms.

ğŸš€ **Advanced Hardware Architecture**: Features a 1024-core NVIDIA Ampere architecture GPU with 32 Tensor Cores, supporting the latest AI frameworks such as TensorFlow and PyTorch.

ğŸ’¾ **High-Speed Memory System**: 8-16GB LPDDR5 memory with bandwidth up to 102.4GB/s, ensuring efficient execution of AI tasks.

ğŸ“¹ **Professional Video Processing**: Supports 4K video codec, 12-channel 1080p30 encoding and 4-channel 4K30 decoding capabilities, suitable for video analysis applications.

ğŸ”Œ **Rich Interface Configuration**: Provides 4 USB 3.2 interfaces, HDMI 2.1, 2 CSI camera interfaces, Gigabit Ethernet, M.2 expansion slots, etc., meeting various application requirements.

reComputer J40x is particularly suitable for robotics, drones, intelligent monitoring, industrial automation, edge AI inference, and other scenarios that require local AI processing capabilities, providing users with professional-grade edge computing solutions.
"""

@app.route('/product/<product_id>')
def product_page(product_id):
    """äº§å“é¡µé¢"""
    product = PRODUCTS_DB.get(product_id, None)
    if not product:
        return "äº§å“ä¸å­˜åœ¨", 404
    
    # è·å–ç”¨æˆ·è¯­è¨€åå¥½ï¼Œé»˜è®¤ä¸ºä¸­æ–‡
    language = session.get('language', 'zh')
    return render_template('product.html', product=product, product_id=product_id, language=language, jetson_ip=JETSON_IP)

@app.route('/api/request_explanation', methods=['POST'])
def request_explanation():
    """è¯·æ±‚äº§å“è®²è§£API"""
    try:
        data = request.get_json()
        product_id = data.get('product_id')
        
        if not product_id:
            return jsonify({'error': 'ç¼ºå°‘äº§å“ID'}), 400
            
        # ç”Ÿæˆè¯·æ±‚ID
        request_id = str(int(time.time()))
        
        # å­˜å‚¨è¯·æ±‚çŠ¶æ€
        request_status[request_id] = {
            'product_id': product_id,
            'status': 'pending',
            'timestamp': time.time()
        }
        
        logger.info(f"æ”¶åˆ°äº§å“è®²è§£è¯·æ±‚ - äº§å“ID: {product_id}, è¯·æ±‚ID: {request_id}")
        
        # è¿™é‡Œå¯ä»¥å‘é€MQTTæ¶ˆæ¯åˆ°æœåŠ¡å™¨
        # ç›®å‰è¿”å›æ¨¡æ‹Ÿå“åº”
        response = {
            'request_id': request_id,
            'status': 'success',
            'message': 'è¯·æ±‚å·²æ¥æ”¶ï¼Œæ­£åœ¨ç”Ÿæˆè®²è§£...',
            'product_id': product_id
        }
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"å¤„ç†è®²è§£è¯·æ±‚æ—¶å‡ºé”™: {e}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@app.route('/api/explanation/<request_id>')
def get_explanation(request_id):
    """è·å–äº§å“è®²è§£ç»“æœ"""
    try:
        if request_id not in request_status:
            return jsonify({'error': 'è¯·æ±‚IDä¸å­˜åœ¨'}), 404
            
        request_info = request_status[request_id]
        product_id = request_info['product_id']
        product = PRODUCTS_DB.get(product_id, None)
        
        if not product:
            return jsonify({'error': 'äº§å“ä¸å­˜åœ¨'}), 404
            
        # æ¨¡æ‹ŸAIè®²è§£ç”Ÿæˆ
        ai_explanation = generate_ai_explanation(product)
        
        response = {
            'request_id': request_id,
            'product_id': product_id,
            'product_name': product['name'],
            'description': product['description'],
            'ai_explanation': ai_explanation,
            'timestamp': int(time.time())
        }
        
        # æ›´æ–°è¯·æ±‚çŠ¶æ€
        request_status[request_id]['status'] = 'completed'
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"è·å–è®²è§£ç»“æœæ—¶å‡ºé”™: {e}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

def generate_ai_explanation(product: Dict[str, Any]) -> str:
    """ç”ŸæˆAIè®²è§£ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    name = product['name']
    features = product['features']
    
    explanation = f"""
æ¬¢è¿äº†è§£æˆ‘ä»¬çš„{name}ï¼

{product['description']}

è®©æˆ‘ä¸ºæ‚¨è¯¦ç»†ä»‹ç»è¿™æ¬¾äº§å“çš„ç‰¹è‰²åŠŸèƒ½ï¼š

"""
    
    for i, feature in enumerate(features, 1):
        explanation += f"{i}. {feature}\n"
        
    explanation += f"""
è¿™æ¬¾{name}é‡‡ç”¨äº†æœ€æ–°çš„æŠ€æœ¯ï¼Œä¸ºç”¨æˆ·æä¾›äº†å“è¶Šçš„ä½¿ç”¨ä½“éªŒã€‚
å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä»¬çš„å®¢æœå›¢é˜Ÿéšæ—¶ä¸ºæ‚¨æœåŠ¡ã€‚

æ„Ÿè°¢æ‚¨å¯¹æˆ‘ä»¬äº§å“çš„å…³æ³¨ï¼
"""
    
    return explanation.strip()

@app.route('/api/products')
def get_products():
    """è·å–æ‰€æœ‰äº§å“åˆ—è¡¨"""
    return jsonify(PRODUCTS_DB)

@app.route('/api/product/<product_id>')
def get_product(product_id):
    """è·å–å•ä¸ªäº§å“ä¿¡æ¯"""
    product = PRODUCTS_DB.get(product_id, None)
    if not product:
        return jsonify({'error': 'äº§å“ä¸å­˜åœ¨'}), 404
    
    return jsonify(product)

@app.errorhandler(404)
def not_found(error):
    """404é”™è¯¯å¤„ç†"""
    return jsonify({'error': 'é¡µé¢ä¸å­˜åœ¨'}), 404

@app.errorhandler(500)
def internal_error(error):
    """500é”™è¯¯å¤„ç†"""
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

def main():
    """ä¸»å‡½æ•°"""
    logger.info(f"å¯åŠ¨WebæœåŠ¡å™¨ {FLASK_HOST}:{FLASK_PORT}")
    app.run(host=FLASK_HOST, port=FLASK_PORT, debug=True)

if __name__ == "__main__":
    main()
